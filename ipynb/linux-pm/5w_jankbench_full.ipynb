{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff00232a-a2be-48c0-8937-abe3a0e99418",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd20c6-2560-4f7a-9df2-c9a1413b7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from lisa.utils import setup_logging\n",
    "from tabulate import tabulate\n",
    "\n",
    "from lisa.trace import Trace\n",
    "from lisa.wa import WAOutput\n",
    "from lisa.stats import Stats\n",
    "from lisa.datautils import series_mean\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "from bokeh.themes import built_in_themes\n",
    "\n",
    "setup_logging(level=logging.CRITICAL)\n",
    "\n",
    "hv.renderer('bokeh').theme = built_in_themes['dark_minimal']\n",
    "pio.templates.default = \"plotly\"\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "color_cycle = hv.Cycle(['#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A', '#19D3F3', '#FF6692', '#B6E880', '#FF97FF', '#FECB52'])\n",
    "\n",
    "opts.defaults(\n",
    "    opts.Curve(tools=['hover'], show_grid=True, color=color_cycle, muted_alpha=0),\n",
    "    opts.Bars(tools=['hover'], show_grid=True, color=color_cycle, muted_alpha=0),\n",
    "    opts.Table(bgcolor='black')\n",
    ")\n",
    "\n",
    "BENCHMARK_PATH = '/home/kajpuc01/power/pixel6/jankbench/'\n",
    "\n",
    "def trim_number(x):\n",
    "    if x > 1000000000:\n",
    "        return f\"{round(x / 1000000000, 3)}B\"\n",
    "    if x > 1000000:\n",
    "        return f\"{round(x / 1000000, 3)}M\"\n",
    "    if x > 10000:\n",
    "        return f\"{round(x / 1000, 2)}k\"\n",
    "    if x < 0.01:\n",
    "        return f\"{round(x * 1000000, 2)}Î¼\"\n",
    "    return str(x)\n",
    "\n",
    "def format_percentage(vals, perc, pvals, pval_threshold=0.02):\n",
    "    result = round(perc, 2).astype(str).apply(lambda s: f\"({'' if s.startswith('-') or (s == '0.0') else '+'}{s}%)\").to_frame()\n",
    "    result['vals'] = vals.apply(lambda x: trim_number(x))\n",
    "    result['pvals'] = pvals\n",
    "    result['pval_marker'] = pvals.apply(lambda x: \"* \" if x < pval_threshold else \"\")\n",
    "    result['value'] = result['vals'] + \" \" + result['pval_marker'] + result['value']\n",
    "    return result['value']\n",
    "\n",
    "def plot_gmean_bars(df, x='stat', y='value', facet_col='metric', facet_col_wrap=3, title='', width=800, height=600, gmean_round=1, include_columns=[], order_cluster=False, table_sort=None, sort_ascending=False, include_total=False, debug=False):\n",
    "    shown_clusters = clusters if not include_total else clusters_total\n",
    "    \n",
    "    if not 'unit' in df.columns:\n",
    "        df['unit'] = 'x'\n",
    "    if not 'metric' in df.columns:\n",
    "        df['metric'] = 'gmean'\n",
    "        \n",
    "    if debug:\n",
    "        print('df')\n",
    "        display(df)\n",
    "        \n",
    "    # compute percentage differences\n",
    "    stats_perc = Stats(df, ref_group={'wa_path': a_wa_path}, value_col=y, agg_cols=['iteration'], stats={'gmean': sp.stats.gmean}, mean_kind_col='gmean').df\n",
    "    # re-add stub a_wa_path\n",
    "    stats_perc_values_temp = stats_perc.query(\"wa_path == @b_wa_path\")\n",
    "    stats_perc_values_temp['wa_path'] = a_wa_path\n",
    "    stats_perc_values_temp['value'] = 0\n",
    "    # re-combine a df with percentage differences\n",
    "    stats_perc_values = pd.concat([stats_perc_values_temp, stats_perc])\n",
    "    stats_perc_values['order_kernel'] = stats_perc_values['wa_path'].map(lambda x: wa_paths.index(x))\n",
    "    \n",
    "    sort_list = ['metric']\n",
    "    \n",
    "    if order_cluster:\n",
    "        sort_list.append('order_cluster')\n",
    "        stats_perc_values['order_cluster'] = stats_perc_values['cluster'].map(lambda x: shown_clusters.index(x))\n",
    "        \n",
    "    sort_list.append('order_kernel')\n",
    "\n",
    "    # split into dfs with percentages and pvalues\n",
    "    \n",
    "    stats_perc_pvalues = stats_perc_values.query(\"stat == 'ks2samp_test'\").sort_values(by=sort_list).reset_index(drop=True)\n",
    "    stats_perc_values = stats_perc_values.query(\"stat == 'gmean'\").sort_values(by=sort_list).reset_index(drop=True)\n",
    "\n",
    "    if debug:\n",
    "        print('stats_perc_values')\n",
    "        display(stats_perc_values)\n",
    "        \n",
    "    # compute absolute gmeans\n",
    "    gmeans = Stats(df, agg_cols=['iteration'], stats={'gmean': sp.stats.gmean, 'std': None, 'sem': None}, mean_kind_col='gmean').df\n",
    "    if gmean_round > 0:\n",
    "        gmeans['value'] = round(gmeans['value'], gmean_round)\n",
    "    gmeans['order_kernel'] = gmeans['wa_path'].map(lambda x: wa_paths.index(x))\n",
    "    \n",
    "    if order_cluster:\n",
    "        gmeans['order_cluster'] = gmeans['cluster'].map(lambda x: shown_clusters.index(x))\n",
    "        \n",
    "    if debug:\n",
    "        display(stats_perc_pvalues)\n",
    "        display(gmeans)\n",
    "\n",
    "    gmeans_mean = gmeans.query(\"stat == 'gmean'\").sort_values(by=sort_list).reset_index(drop=True)\n",
    "    if debug:\n",
    "        print(sort_list)\n",
    "        print('gmeans')\n",
    "        display(gmeans)\n",
    "        \n",
    "    data_table_cols = [col for col in gmeans_mean.columns if col in (['wa_path', 'value', 'test_name', 'variable', 'metric', 'chan_name', 'comm'] + include_columns)]\n",
    "    data_table = gmeans_mean[data_table_cols].rename(columns={'wa_path':'kernel'})\n",
    "    data_table['perc_diff'] = stats_perc_values['value'].map(lambda x: str(round(x, 2)) + '%')\n",
    "    data_table['value'] = data_table['value'].apply(lambda x: trim_number(x))\n",
    "    if table_sort is not None:\n",
    "        data_table = data_table.sort_values(by=table_sort)\n",
    "    ptable(data_table)\n",
    "        \n",
    "    # plot bars\n",
    "    fig = px.bar(gmeans_mean, x=x, y=y, color='wa_path', facet_col=facet_col, facet_col_wrap=facet_col_wrap, barmode='group', text=format_percentage(gmeans_mean['value'], stats_perc_values['value'], stats_perc_pvalues['value']), title=title, width=width, height=height)\n",
    "    fig.update_traces(textposition='outside')\n",
    "    fig.update_yaxes(matches=None)\n",
    "    if sort_ascending:\n",
    "        fig.update_xaxes(categoryorder='total ascending')\n",
    "    fig.show()\n",
    "\n",
    "    return data_table\n",
    "    \n",
    "def ptable(df):\n",
    "    print(tabulate(df, headers='keys', tablefmt='pretty', showindex=False, floatfmt=\".3f\"))\n",
    "\n",
    "    \n",
    "def trim_wa_path(path):\n",
    "    return path[10:-8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e20065-b59c-4d93-9fc2-d828c929f174",
   "metadata": {},
   "source": [
    "## Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10a2149-063b-41e2-b974-8ee64d8d9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_name_a = 'jankbench_baseline_60hz_10_0812'\n",
    "benchmark_name_b = 'jankbench_eas_lock_60hz_10_1301'\n",
    "benchmark_name_c = 'jankbench_ufc_eas_lock_60hz_10_1201'\n",
    "benchmark_name_d = 'jankbench_ufc_feec_all_cpus_10_3001'\n",
    "benchmark_name_e = 'jankbench_ufc_feec_all_cpus_fits_10_3001'\n",
    "\n",
    "wa_output_a = WAOutput(BENCHMARK_PATH + benchmark_name_a)\n",
    "wa_output_b = WAOutput(BENCHMARK_PATH + benchmark_name_b)\n",
    "wa_output_c = WAOutput(BENCHMARK_PATH + benchmark_name_c)\n",
    "wa_output_d = WAOutput(BENCHMARK_PATH + benchmark_name_d)\n",
    "wa_output_e = WAOutput(BENCHMARK_PATH + benchmark_name_e)\n",
    "\n",
    "df_a = wa_output_a['results'].df\n",
    "df_b = wa_output_b['results'].df\n",
    "df_c = wa_output_c['results'].df\n",
    "df_d = wa_output_d['results'].df\n",
    "df_e = wa_output_e['results'].df\n",
    "\n",
    "df_jank_a = wa_output_a['jankbench'].df\n",
    "df_jank_b = wa_output_b['jankbench'].df\n",
    "df_jank_c = wa_output_c['jankbench'].df\n",
    "df_jank_d = wa_output_d['jankbench'].df\n",
    "df_jank_e = wa_output_e['jankbench'].df\n",
    "\n",
    "a_kernel = df_a['kernel'][0]\n",
    "b_kernel = df_b['kernel'][0]\n",
    "c_kernel = df_c['kernel'][0]\n",
    "d_kernel = df_d['kernel'][0]\n",
    "e_kernel = df_e['kernel'][0]\n",
    "\n",
    "a_wa_path = trim_wa_path(df_a['wa_path'][0])\n",
    "b_wa_path = trim_wa_path(df_b['wa_path'][0])\n",
    "c_wa_path = trim_wa_path(df_c['wa_path'][0])\n",
    "d_wa_path = trim_wa_path(df_d['wa_path'][0])\n",
    "e_wa_path = trim_wa_path(df_e['wa_path'][0])\n",
    "wa_paths = [a_wa_path, b_wa_path, c_wa_path, d_wa_path, e_wa_path]\n",
    "\n",
    "df = pd.concat([df_a, df_b, df_c, df_d, df_e])\n",
    "df_jank = pd.concat([df_jank_a, df_jank_b, df_jank_c, df_jank_d, df_jank_e])\n",
    "df = df.drop(columns=['scaled from(%)'])\n",
    "df['wa_path'] = trim_wa_path(df['wa_path'].str)\n",
    "df_jank['wa_path'] = trim_wa_path(df_jank['wa_path'].str)\n",
    "df_perf = df[df['metric'].str.contains('perf')].reset_index(drop=True).query(\"value != 0\")\n",
    "df_perf['metric'] = df_perf['metric'].str[7:]\n",
    "df = df[~df['metric'].str.contains('perf')].reset_index(drop=True).query(\"value != 0\")\n",
    "\n",
    "clusters = ['little', 'mid', 'big']\n",
    "clusters_total = ['little', 'mid', 'big', 'total']\n",
    "\n",
    "df_jank_mean_duration = df_jank.query(\"variable == 'total_duration'\")[[\"wa_path\", \"iteration\", \"value\"]].groupby([\"wa_path\", \"iteration\"]).agg(lambda x: series_mean(x)).reset_index()\n",
    "df_jank_frame_count = len(df_jank.query(\"variable == 'jank_frame'\"))\n",
    "df_jank_percs = df_jank.query(\"variable == 'jank_frame'\").groupby(['wa_path', 'iteration']).size().reset_index().rename(columns={0:'count'})\n",
    "df_jank_percs['jank_count'] = df_jank.query(\"variable == 'jank_frame' and value == 1.0\").groupby(['wa_path', 'iteration']).size().reset_index().rename(columns={0:'count'})['count']\n",
    "df_jank_percs['perc'] = round(df_jank_percs['jank_count'] / df_jank_percs['count'] * 100, 2)\n",
    "\n",
    "print(benchmark_name_a, benchmark_name_b, benchmark_name_c, benchmark_name_d, benchmark_name_e)\n",
    "\n",
    "print(wa_paths)\n",
    "print(a_kernel, b_kernel, c_kernel, d_kernel, e_kernel)\n",
    "\n",
    "display(df)\n",
    "display(df_jank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f367aadf-d0db-46a7-a147-246d17358d65",
   "metadata": {},
   "source": [
    "# Benchmark scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64855b6b-d9a7-4214-aaec-5fce720aa8fb",
   "metadata": {},
   "source": [
    "## Max frame durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b74a3f-843b-4a57-9a7f-598e1a9c9f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_durations = df_jank.query(\"variable == 'total_duration'\")[[\"wa_path\", \"iteration\", \"value\"]].groupby([\"wa_path\"]).max().reset_index()\n",
    "max_durations['variable'] = 'max_duration'\n",
    "max_durations = plot_gmean_bars(max_durations, x='variable', y='value', title='jankbench max frame duration', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f67f101-e3b1-49c2-8628-b739d90a1785",
   "metadata": {},
   "source": [
    "## Line plot - frame duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7e34f4-44e6-4ad5-a2c4-75d2ef226366",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hv.Dataset(df_jank_mean_duration, ['iteration', hv.Dimension('wa_path', values=wa_paths)], 'value')\n",
    "layout = ds.to(hv.Curve, 'iteration', 'value').overlay('wa_path').opts(legend_position='bottom').opts(shared_axes=False, title='Jankbench mean frame duration per-iteration')\n",
    "layout.opts(\n",
    "    opts.Curve(height=600, width=1500, axiswise=True, shared_axes=False),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7808c41a-06f0-46e9-ac0d-1bae6d8fafee",
   "metadata": {},
   "source": [
    "## Overall frame durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a2b7f2-36a3-4650-8d10-c4a3aa2261b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jank_mean_duration['variable'] = 'mean_duration'\n",
    "df_jank_mean_duration\n",
    "mean_durations = plot_gmean_bars(df_jank_mean_duration, x='variable', y='value', title='jankbench gmean frame duration', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0f11d8-f621-4a52-bea1-8fe486e14d6e",
   "metadata": {},
   "source": [
    "## Frame duration histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52cacc2-7999-468e-8f03-4bd866fc05fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_jank.query(\"variable == 'total_duration'\"), x='value', color='wa_path', barmode='group', nbins=40, height=800, title='Jankench frame duration histogram')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a0b6cd-9170-4c46-abd7-f88601c40e3c",
   "metadata": {},
   "source": [
    "## Frame duration ecdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1cb1d4-eb70-4db6-896a-31e8fcf15e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.ecdf(df_jank.query(\"variable == 'total_duration'\"), x='value', color='wa_path', height=800, title='')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623031bc-1d3c-4d6a-95f7-d96c9ea62f1c",
   "metadata": {},
   "source": [
    "## Overall jank percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe8d780-cd13-4e1e-929b-289b9963b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hv.Dataset(df_jank_percs, ['iteration', hv.Dimension('wa_path', values=wa_paths)], 'perc')\n",
    "layout = ds.to(hv.Curve, 'iteration', 'perc').overlay('wa_path').opts(legend_position='bottom').opts(shared_axes=False, title='Jankbench jank percentage per-iteration')\n",
    "layout.opts(\n",
    "    opts.Curve(height=600, width=1500, axiswise=True, shared_axes=False),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8384c4b0-a8f8-4aa6-923d-31bbc2f8c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jank_percs['value'] = df_jank_percs['perc']\n",
    "df_jank_percs['variable'] = 'jank_perc'\n",
    "jank_percs = plot_gmean_bars(df_jank_percs[['wa_path', 'iteration', 'value', 'variable']], x='variable', y='value', title='jankbench gmean jank percentage', width=1000, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bcdb31-01dd-46bf-ab44-fb545c218bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hv.Dataset(df, ['iteration', hv.Dimension('wa_path', values=wa_paths), 'test_name', 'metric'], 'value')\n",
    "layout = ds.to(hv.Curve, 'iteration', 'value').overlay('wa_path').opts(legend_position='bottom').layout('test_name').opts(shared_axes=False, title='Jankbench metric per-iteration').cols(3)\n",
    "layout.opts(\n",
    "    opts.Curve(height=600, width=500, axiswise=True, shared_axes=False),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0767de4-b599-4321-aedb-c335d9ac730b",
   "metadata": {},
   "source": [
    "## Bar plot - jank percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3f07e4-a7e7-4c39-81b4-a56583dc13af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(df.query(\"metric == 'jank_p'\"), x='stat', y='value', facet_col='test_name', facet_col_wrap=4, title='jankbench gmean jank percentage', width=1600, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd6b97f-958c-4686-bddb-574a551c7ea7",
   "metadata": {},
   "source": [
    "## Bar plot - mean duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e166d27b-6b76-40d8-b5b4-f382f3bed602",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(df.query(\"metric == 'mean'\"), x='stat', y='value', facet_col='test_name', facet_col_wrap=4, title='jankbench gmean frame duration', width=1600, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdacf327-0709-479a-a241-552ecf6fad2c",
   "metadata": {},
   "source": [
    "# Overutilized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce155c4e-70a6-4ea7-af42-915121c909bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    overutils = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/overutilized.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/overutilized.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/overutilized.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/overutilized.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/overutilized.pqt'),\n",
    "    ]\n",
    "    \n",
    "    overutilized_combined = pd.concat(overutils)\n",
    "    overutilized_combined['wa_path'] = trim_wa_path(overutilized_combined['wa_path'].str)\n",
    "    overutilized_combined['time'] = round(overutilized_combined['time'], 2)\n",
    "    overutilized_combined['total_time'] = round(overutilized_combined['total_time'], 2)\n",
    "    \n",
    "    overutilized_mean = overutilized_combined.groupby(['wa_path']).agg(lambda x: series_mean(x)).reset_index().rename(columns={'wa_path':'kernel'})\n",
    "    overutilized_mean['metric'] = 'overutilized'\n",
    "    overutilized_mean = overutilized_mean[['metric', 'kernel', 'time', 'total_time', 'percentage']]\n",
    "    overutilized_mean['percentage'] = round(overutilized_mean['percentage'], 2)\n",
    "    overutilized_mean['time'] = round(overutilized_mean['time'], 2)\n",
    "    overutilized_mean['total_time'] = round(overutilized_mean['total_time'], 2)\n",
    "\n",
    "    ptable(overutilized_mean)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print('overutilized.pqt not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33212c12-b81f-4755-9fd9-6309269a6103",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afff0d2-4567-4747-bfc8-59b4b8e19162",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(overutilized_combined, x='iteration', y='percentage', color='wa_path', height=600, title='Overutilized percentage per-iteration')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41063ef2-6933-4a5f-9a4d-3c2102e2b051",
   "metadata": {},
   "source": [
    "# Perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eaab41-98e1-4510-8104-afdab8d7ea89",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76015fad-1b2c-42b3-b51a-ef3fa2e213fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['cpu-migrations', 'context-switches', 'stalled-cycles-backend', 'page-faults', 'major-faults', 'cache-misses', 'instructions', 'cpu-cycles', 'cpu-clock']\n",
    "ds = hv.Dataset(df_perf, ['iteration', hv.Dimension('wa_path', values=wa_paths), hv.Dimension('metric', values=metrics)], 'value')\n",
    "layout = ds.select(metric=metrics).to(hv.Curve, 'iteration', 'value').overlay('wa_path').opts(legend_position='bottom').layout('metric').opts(shared_axes=False, title='Perf counters').cols(3)\n",
    "layout.opts(\n",
    "    opts.Curve(width=600, height=340),\n",
    "    opts.Overlay(legend_position='bottom'),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27799672-3e88-4d8f-872a-744661ac5fde",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e024f-4504-4243-bd80-77ae9412d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['cpu-migrations', 'context-switches', 'stalled-cycles-backend', 'page-faults', 'major-faults', 'minor-faults', 'cache-misses', 'instructions', 'cpu-cycles', 'cpu-clock']\n",
    "plot_gmean_bars(df_perf.query(\"metric in @metrics\"), x='stat', y='value', facet_col='metric', facet_col_wrap=5, title='gmean perf counters', width=1900, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d8f0fb-a413-47eb-8fcf-e026f976d67c",
   "metadata": {},
   "source": [
    "# Idle residency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc982f-a400-4a41-aedf-dcf5565ac62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    idle_residencies = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/idle_residency.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/idle_residency.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/idle_residency.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/idle_residency.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/idle_residency.pqt'),\n",
    "    ]\n",
    "    \n",
    "    idle_residency_times_combined = pd.concat(idle_residencies)\n",
    "    idle_residency_times_combined['wa_path'] = trim_wa_path(idle_residency_times_combined['wa_path'].str)\n",
    "\n",
    "    residency_data = idle_residency_times_combined.groupby(['wa_path', 'cluster', 'idle_state'], sort=False).mean().reset_index()[['wa_path', 'cluster', 'idle_state', 'time']]\n",
    "    residency_data['time'] = round(residency_data['time'], 2)\n",
    "    \n",
    "    display(idle_residency_times_combined)\n",
    "except FileNotFoundError:\n",
    "    print('idle_residency.pqt not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9265a2af-4f08-4767-8c36-4cc794d50d4a",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f46686-8970-4799-b7f0-af4b5ccefd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(residency_data, x='idle_state', y='time', color='wa_path', facet_col='cluster', barmode='group', text=residency_data['time'], width=1900, height=600, title='Idle state residencies')\n",
    "fig.update_traces(textposition='outside')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0e4a6-30a9-42fd-bfad-5f4da92e96b8",
   "metadata": {},
   "source": [
    "# Idle misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7652f5b4-4c0e-4177-8ecc-35269153f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cpu_idle_a = pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/cpu_idle.pqt')\n",
    "    cpu_idle_b = pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/cpu_idle.pqt')\n",
    "    cpu_idle_c = pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/cpu_idle.pqt')\n",
    "    cpu_idle_d = pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/cpu_idle.pqt')\n",
    "    cpu_idle_e = pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/cpu_idle.pqt')\n",
    "    cpu_idle_a_wakeups = len(cpu_idle_a.query(\"state == 4294967295\"))\n",
    "    cpu_idle_b_wakeups = len(cpu_idle_b.query(\"state == 4294967295\"))\n",
    "    cpu_idle_c_wakeups = len(cpu_idle_c.query(\"state == 4294967295\"))\n",
    "    cpu_idle_d_wakeups = len(cpu_idle_d.query(\"state == 4294967295\"))\n",
    "    cpu_idle_e_wakeups = len(cpu_idle_d.query(\"state == 4294967295\"))\n",
    "except FileNotFoundError:\n",
    "    print('cpu_idle.pqt not found.')\n",
    "\n",
    "try:\n",
    "    cpu_idle_miss_a = pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/cpu_idle_miss_counts.pqt')\n",
    "    cpu_idle_miss_a['count_perc'] = round(cpu_idle_miss_a['count'] / cpu_idle_a_wakeups * 100, 3)\n",
    "    cpu_idle_miss_b = pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/cpu_idle_miss_counts.pqt')\n",
    "    cpu_idle_miss_b['count_perc'] = round(cpu_idle_miss_b['count'] / cpu_idle_b_wakeups * 100, 3)\n",
    "    cpu_idle_miss_c = pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/cpu_idle_miss_counts.pqt')\n",
    "    cpu_idle_miss_c['count_perc'] = round(cpu_idle_miss_c['count'] / cpu_idle_c_wakeups * 100, 3)\n",
    "    cpu_idle_miss_d = pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/cpu_idle_miss_counts.pqt')\n",
    "    cpu_idle_miss_d['count_perc'] = round(cpu_idle_miss_d['count'] / cpu_idle_d_wakeups * 100, 3)\n",
    "    cpu_idle_miss_e = pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/cpu_idle_miss_counts.pqt')\n",
    "    cpu_idle_miss_e['count_perc'] = round(cpu_idle_miss_e['count'] / cpu_idle_e_wakeups * 100, 3)\n",
    "    \n",
    "    cpu_idle_miss_combined = pd.concat([cpu_idle_miss_a, cpu_idle_miss_b, cpu_idle_miss_c, cpu_idle_miss_d, cpu_idle_miss_e])\n",
    "    cpu_idle_miss_combined['type'] = cpu_idle_miss_combined['below'].replace(0, 'too deep').replace(1, 'too shallow')\n",
    "    cpu_idle_miss_combined['wa_path'] = trim_wa_path(cpu_idle_miss_combined['wa_path'].str)\n",
    "    \n",
    "    display(cpu_idle_miss_combined)\n",
    "    \n",
    "    a_miss_percentage = round(cpu_idle_miss_a['count'].sum() / cpu_idle_a_wakeups * 100, 3)\n",
    "    b_miss_percentage = round(cpu_idle_miss_b['count'].sum() / cpu_idle_b_wakeups * 100, 3)\n",
    "    c_miss_percentage = round(cpu_idle_miss_c['count'].sum() / cpu_idle_c_wakeups * 100, 3)\n",
    "    d_miss_percentage = round(cpu_idle_miss_d['count'].sum() / cpu_idle_d_wakeups * 100, 3)\n",
    "    e_miss_percentage = round(cpu_idle_miss_e['count'].sum() / cpu_idle_e_wakeups * 100, 3)\n",
    "    print(f\"{a_miss_percentage}% {a_wa_path} vs {b_miss_percentage}% {b_wa_path}\")\n",
    "    print(f\"{c_miss_percentage}% {c_wa_path} vs {d_miss_percentage}% {d_wa_path}\")\n",
    "    print(f\"{a_miss_percentage}% {a_wa_path} vs {e_miss_percentage}% {e_wa_path}\")\n",
    "except FileNotFoundError:\n",
    "    print('cpu_idle_miss_counts.pqt not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854705ab-ec32-47e8-8f2d-c64d010d946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptable(cpu_idle_miss_combined.groupby(['wa_path', 'type']).sum().reset_index()[['wa_path', 'type', 'count_perc']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85154dbd-7e6d-42e5-ab77-ca8bf244d810",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad450e7-4f26-4ee6-be9c-c2b33707b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(cpu_idle_miss_combined, x='type', y='count_perc', color='wa_path', facet_col='cluster', barmode='group', text=cpu_idle_miss_combined['count_perc'], width=1800, height=600, title='CPUIdle misses as percentage of all wakeups')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef18dfd4-9020-4666-8cb9-55021e206840",
   "metadata": {},
   "source": [
    "# Power usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03562334-977f-4f5e-ae5a-4c88d9767b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pixel6_emeters = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/pixel6_emeter.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/pixel6_emeter.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/pixel6_emeter.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/pixel6_emeter.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/pixel6_emeter.pqt'),\n",
    "    ]\n",
    "    \n",
    "    pixel6_emeter_means = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/pixel6_emeter_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/pixel6_emeter_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/pixel6_emeter_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/pixel6_emeter_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/pixel6_emeter_mean.pqt'),\n",
    "    ]\n",
    "    \n",
    "    pixel6_emeters_combined = pd.concat(pixel6_emeters)\n",
    "    pixel6_emeters_combined['wa_path'] = trim_wa_path(pixel6_emeters_combined['wa_path'].str)\n",
    "    pixel6_emeter_means_combined = pd.concat(pixel6_emeter_means)\n",
    "    pixel6_emeter_means_combined['total_power'] = pixel6_emeter_means_combined[['little_power', 'mid_power', 'big_power']].sum(axis=1)\n",
    "    pixel6_emeter_means_combined['wa_path'] = trim_wa_path(pixel6_emeter_means_combined['wa_path'].str)\n",
    "    \n",
    "    pixel6_emeter_melt = pd.melt(pixel6_emeter_means_combined, id_vars=['iteration', 'wa_path', 'kernel'], value_vars=['little_power', 'mid_power', 'big_power', 'total_power'])\n",
    "    pixel6_emeter_melt['cluster'] = pixel6_emeter_melt['chan_name'].str[:-6]\n",
    "except FileNotFoundError:\n",
    "    print('pixel6_emeter.pqt not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6618dc-34d2-4f55-937a-0644ad9424ae",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1b971-a771-47ac-bc3c-c23b4dda5fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(pixel6_emeter_melt, x='iteration', y='value', color='wa_path', facet_col='cluster', height=600, title='Mean power usage across iterations [mW]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5eb606-bc8e-4b3e-8bab-2e11eb28d6e4",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2de01-0fee-4f19-ba49-aa99c3e59430",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_usage = plot_gmean_bars(pixel6_emeter_melt, x='chan_name', y='value', facet_col='metric', facet_col_wrap=5, title='Gmean power usage [mW]', width=1800, height=600, order_cluster=True, include_columns=['chan_name'], include_total=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd1da00-5be2-41fb-879f-3d1accad3eaa",
   "metadata": {},
   "source": [
    "# Energy estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52cec23-aa7b-4f47-95ea-a2b992719a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    energy_estimate_means = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/energy_estimate_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/energy_estimate_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/energy_estimate_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/energy_estimate_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/energy_estimate_mean.pqt'),\n",
    "    ]\n",
    "    \n",
    "    energy_estimate_means_combined = pd.concat(energy_estimate_means)\n",
    "    energy_estimate_means_combined['wa_path'] = energy_estimate_means_combined['wa_path'].str[20:-8]\n",
    "except FileNotFoundError:\n",
    "    print('energy_estimate_mean.pqt not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab2574e-3524-4567-8c90-bfc38aadfefd",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dc154d-9235-44f9-a759-17715fd83a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_estimate_melt = pd.melt(energy_estimate_means_combined, id_vars=['iteration', 'wa_path'], value_vars=['little', 'mid', 'big', 'total']).rename(columns={'variable':'cluster'})\n",
    "ds = hv.Dataset(energy_estimate_melt, ['iteration', hv.Dimension('wa_path', values=wa_paths), hv.Dimension('cluster', values=clusters_total)], 'value')\n",
    "layout = ds.to(hv.Curve, 'iteration', 'value').overlay('wa_path').opts(legend_position='bottom').layout('cluster').cols(3).opts(title='Mean energy estimate across iterations')\n",
    "layout.opts(\n",
    "    opts.Curve(width=600, height=600, ylabel='mW'),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f684ff30-9611-4066-9a61-6c81961f1d6c",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c37728d-e6b2-47d6-9169-216e2ba8684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(energy_estimate_melt, x='cluster', y='value', facet_col='metric', facet_col_wrap=5, title='Gmean energy estimate [bW]', width=1800, height=600, order_cluster=True, include_total=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c462a9-a006-4d33-81e7-0b63325c75c4",
   "metadata": {},
   "source": [
    "# Thermal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca56d6f-a22f-47ba-bb3b-90299c5cd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    thermals = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/thermal.pqt').groupby(['iteration', 'kernel', 'wa_path']).agg(lambda x: series_mean(x)).reset_index(),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/thermal.pqt').groupby(['iteration', 'kernel', 'wa_path']).agg(lambda x: series_mean(x)).reset_index(),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/thermal.pqt').groupby(['iteration', 'kernel', 'wa_path']).agg(lambda x: series_mean(x)).reset_index(),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/thermal.pqt').groupby(['iteration', 'kernel', 'wa_path']).agg(lambda x: series_mean(x)).reset_index(),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/thermal.pqt').groupby(['iteration', 'kernel', 'wa_path']).agg(lambda x: series_mean(x)).reset_index(),\n",
    "    ]\n",
    "    \n",
    "    for i in range(len(thermals)):\n",
    "        for col in [c for c in thermals[i].columns if c not in ['time', 'iteration', 'kernel', 'wa_path']]:\n",
    "            thermals[i][col] = thermals[i][col] / 1000\n",
    "        thermals[i] = round(thermals[i], 2)\n",
    "        thermals[i]['wa_path'] = thermals[i]['wa_path'].str[20:-8]\n",
    "\n",
    "    thermal_combined = pd.concat(thermals)\n",
    "    thermal_melt = pd.melt(thermal_combined, id_vars=['iteration', 'wa_path', 'kernel'], value_vars=['little', 'mid', 'big']).rename(columns={'variable':'cluster'})\n",
    "    \n",
    "    display(thermal_melt)\n",
    "except FileNotFoundError:\n",
    "    print('thermal.pqt not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0efab5b-80b0-4e5a-a076-b62a1508a492",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11d42f-6073-486b-98ab-658d0104f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hv.Dataset(thermal_melt, ['iteration', hv.Dimension('wa_path', values=wa_paths), hv.Dimension('cluster', values=clusters)], 'value')\n",
    "layout = ds.to(hv.Curve, 'iteration', 'value').overlay('wa_path').opts(legend_position='bottom').layout('cluster').opts(title='Mean cluster temperature across iterations')\n",
    "layout.opts(\n",
    "    opts.Curve(width=800, height=600, ylabel='temperature'),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f266d7a-2386-445f-8987-d0baaefb3a5b",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71afecc5-68f5-429e-b9b8-f359a9aebfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "thermal = plot_gmean_bars(thermal_melt, x='cluster', y='value', facet_col='metric', facet_col_wrap=2, title='Gmean temperature', include_columns=['cluster'], width=1800, height=600, order_cluster=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc02cb0-0bcc-4367-bc37-8120108ec70e",
   "metadata": {},
   "source": [
    "# Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e5880b-88c0-424e-94f5-2635a26884e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    freqs_means = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/freqs_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/freqs_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/freqs_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/freqs_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/freqs_mean.pqt'),\n",
    "    ]\n",
    "    \n",
    "    freqs_mean_combined = pd.concat(freqs_means)\n",
    "    freqs_mean_combined['wa_path'] = trim_wa_path(freqs_mean_combined['wa_path'].str)\n",
    "    freqs_mean_combined['unit'] = 'MHz'\n",
    "    freqs_mean_combined['metric'] = 'frequency'\n",
    "    freqs_mean_combined['order'] = freqs_mean_combined['cluster'].replace('little', 0).replace('mid', 1).replace('big', 2)\n",
    "    freqs_mean_combined = freqs_mean_combined.sort_values(by=['iteration', 'order']).rename(columns={'frequency':'value'})\n",
    "\n",
    "    display(freqs_mean_combined.head())\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found. ({e})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d1e3ef-7665-4b99-b3b8-3c8bec6dc4b7",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca933d3-916d-4656-9613-9aa991b708f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hv.Dataset(freqs_mean_combined, ['iteration', hv.Dimension('wa_path', values=wa_paths), hv.Dimension('cluster', values=clusters)], 'value')\n",
    "layout = ds.to(hv.Curve, 'iteration', 'value').overlay('wa_path').opts(legend_position='bottom').layout('cluster').opts(title='Mean cluster frequency across iterations')\n",
    "layout.opts(\n",
    "    opts.Curve(width=600, height=600, ylabel='MHz'),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e2bc5-5ddc-4627-850d-e5e27b683e53",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb72d9b-f40f-4428-a8bd-0cd2e19d7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(freqs_mean_combined, x='metric', y='value', facet_col='cluster', facet_col_wrap=3, title='Gmean frequency per cluster', width=1800, height=600, order_cluster=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93c6cb7-86e9-4a3d-afa0-792aa953c70f",
   "metadata": {},
   "source": [
    "# CFS signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814340a-e6bf-4356-964e-6fa341c17842",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs_signals_a = pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/sched_pelt_cfs_mean.pqt')\n",
    "cfs_signals_b = pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/sched_pelt_cfs_mean.pqt')\n",
    "cfs_signals_c = pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/sched_pelt_cfs_mean.pqt')\n",
    "cfs_signals_d = pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/sched_pelt_cfs_mean.pqt')\n",
    "\n",
    "cfs_signals_combined = pd.concat([cfs_signals_a, cfs_signals_b, cfs_signals_c, cfs_signals_d])\n",
    "cfs_signals_combined['wa_path'] = trim_wa_path(cfs_signals_combined['wa_path'].str)\n",
    "cfs_signals_combined['kernel'] = 'android-mainline-5.18'\n",
    "\n",
    "cfs_signals_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b528221-8603-4227-9493-d5062d9c18ef",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5bb4c6-fc80-47ac-ad0c-2af15505b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = ['util', 'load']\n",
    "ds = hv.Dataset(cfs_signals_combined, ['iteration', hv.Dimension('wa_path', values=wa_paths), hv.Dimension('cluster', values=clusters)], signals)\n",
    "layout = hv.Layout([ds.to(hv.Curve, 'iteration', signal).overlay('wa_path').opts(legend_position='bottom').layout('cluster').opts(title='Mean cluster ' + signal) for signal in signals]).cols(1)\n",
    "layout.opts(\n",
    "    opts.Curve(width=600, height=400),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f95971-59c6-45d4-9895-937c42fb082c",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc087f-c2a2-4061-835f-eeeda2e757c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs_signals_melt = pd.melt(cfs_signals_combined, id_vars=['iteration', 'wa_path', 'kernel', 'cluster'], value_vars=['util', 'load'])\n",
    "plot_gmean_bars(cfs_signals_melt, x='cluster', y='value', facet_col='variable', facet_col_wrap=1, title='Gmean cfs signals', width=1800, height=1000, order_cluster=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888beb4e-4dff-459b-b859-edcb9d1e7c70",
   "metadata": {},
   "source": [
    "# Wakeup latency - tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d60cf-e9c9-42d2-b1b4-d880057e94bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_important = ['RenderThread', 'droid.benchmark', 'surfaceflinger']\n",
    "\n",
    "wakeup_latencies = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/wakeup_latency.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/wakeup_latency.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/wakeup_latency.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/wakeup_latency.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/wakeup_latency.pqt'),\n",
    "]\n",
    "    \n",
    "wakeup_latency_combined = pd.concat(wakeup_latencies)\n",
    "wakeup_latency_combined = wakeup_latency_combined.query(\"comm in @tasks_important\")\n",
    "wakeup_latency_combined['wa_path'] = trim_wa_path(wakeup_latency_combined['wa_path'].str)\n",
    "wakeup_latency_combined['order'] = wakeup_latency_combined['wa_path'].map(lambda x: wa_paths.index(x))\n",
    "wakeup_latency_combined\n",
    "\n",
    "wakeup_latency_means = [\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/wakeup_latency_mean.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/wakeup_latency_mean.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/wakeup_latency_mean.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/wakeup_latency_mean.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/wakeup_latency_mean.pqt'),\n",
    "]\n",
    "\n",
    "wakeup_latency_mean_combined = pd.concat(wakeup_latency_means).rename(columns={'wakeup_latency':'value'})\n",
    "wakeup_latency_mean_combined = wakeup_latency_mean_combined.query(\"comm in @tasks_important\")\n",
    "wakeup_latency_mean_combined['wa_path'] = trim_wa_path(wakeup_latency_mean_combined['wa_path'].str)\n",
    "wakeup_latency_mean_combined['order'] = wakeup_latency_mean_combined['wa_path'].map(lambda x: wa_paths.index(x))\n",
    "wakeup_latency_mean_combined['unit'] = 'x'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917600bb-5af9-4450-9c1d-54b2f3234ff5",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58193a2-e34c-4ed6-87a6-0c18269a8d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(wakeup_latency_mean_combined, x='iteration', y='value', color='wa_path', facet_col='comm', facet_col_wrap=3, height=500, title='Task wakeup latencies across iterations')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8520262-13e3-41e7-bcf1-e11d6809171f",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98746075-e7c0-4f43-a4ab-4bc7d621799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wakeup_latency = plot_gmean_bars(wakeup_latency_mean_combined, x='metric', y='value', facet_col='comm', facet_col_wrap=3, title='Gmean task wakeup latency', include_columns=['comm'], table_sort=['comm'], gmean_round=0, width=1800, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f279eb66-6130-4e61-8399-a70530241fce",
   "metadata": {},
   "source": [
    "## Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6157250-485d-4979-a194-7d9d5454acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wakeup_latency_quantiles = wakeup_latency_combined.groupby(['comm', 'wa_path', 'iteration']).quantile([0.9, 0.95, 0.99]).reset_index()[['comm', 'wa_path', 'level_3', 'iteration', 'wakeup_latency', 'order']].rename(columns={'level_3':'quantile'}).sort_values(by=['comm', 'order'])\n",
    "wakeup_latency_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98150fc5-f4ce-4ece-8a44-363508669dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(wakeup_latency_quantiles.rename(columns={'wakeup_latency':'value'}), x='quantile', y='value', facet_col='comm', facet_col_wrap=1, title='Gmean latency quantile', include_columns=['quantile', 'comm'], table_sort=['quantile', 'comm'], width=1900, height=1600, gmean_round=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064e84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "test_lats = wakeup_latencies[0].query(\"comm == 'RenderThread'\")\n",
    "test = pd.DataFrame()\n",
    "test_lats_lat = test_lats['wakeup_latency']\n",
    "test['latency'] = test_lats_lat\n",
    "test['cdf'] = ss.norm.cdf(test_lats_lat)\n",
    "\n",
    "fig = px.ecdf(test_lats, x='wakeup_latency')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c8ed8a-39eb-45eb-a04a-afc8e28f778f",
   "metadata": {},
   "source": [
    "# Wakeup latency - cgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dc5ca6-ce88-4270-8759-f9650388cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "wakeup_latencies_cgroup = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/wakeup_latency_cgroup.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/wakeup_latency_cgroup.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/wakeup_latency_cgroup.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/wakeup_latency_cgroup.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/wakeup_latency_cgroup.pqt'),\n",
    "]\n",
    "\n",
    "wakeup_latency_cgroup_combined = pd.concat(wakeup_latencies_cgroup).rename(columns={'wakeup_latency':'value'})\n",
    "wakeup_latency_cgroup_combined['wa_path'] = trim_wa_path(wakeup_latency_cgroup_combined['wa_path'].str)\n",
    "wakeup_latency_cgroup_combined['order'] = wakeup_latency_cgroup_combined['wa_path'].map(lambda x: wa_paths.index(x))\n",
    "\n",
    "wakeup_latency_cgroup_mean = wakeup_latency_cgroup_combined.groupby([\"wa_path\", \"cgroup\", \"iteration\"]).agg(lambda x: series_mean(x)).reset_index()[['wa_path', 'cgroup', 'iteration', 'value', 'order']]\n",
    "wakeup_latency_cgroup_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d25a9a8-8a6c-4e26-86a1-dcbef1d1346c",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c77bb00-804c-4c23-bd73-0f830d2194bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(wakeup_latency_cgroup_mean, x='iteration', y='value', color='wa_path', facet_col='cgroup', facet_col_wrap=3, height=600, title='cgroup wakeup latencies across iterations')\n",
    "fig.update_yaxes(matches=None)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a264e88b-36b4-452c-b0a1-6116497e96a6",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02e21c-5e80-4903-a2f3-23aade1012c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(wakeup_latency_cgroup_mean, x='metric', y='value', facet_col='cgroup', title='Gmean task wakeup latency', include_columns=['cgroup'], table_sort=['cgroup', 'kernel'], gmean_round=0, width=1800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac82863c-db14-4573-9a16-2bb0b3ee9a68",
   "metadata": {},
   "source": [
    "## Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ac56f-593e-4557-807c-9d85d107e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "wakeup_latency_cgroup_quantiles = wakeup_latency_cgroup_mean.groupby(['cgroup', 'wa_path', 'iteration']).quantile([0.9, 0.95, 0.99]).reset_index()[['cgroup', 'wa_path', 'level_3', 'iteration', 'value', 'order']].rename(columns={'level_3':'quantile'}).sort_values(by=['cgroup', 'order'])\n",
    "wakeup_latency_cgroup_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24f710a-ce62-4732-8f6c-6cc5854efe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(wakeup_latency_cgroup_quantiles, x='quantile', y='value', facet_col='cgroup', facet_col_wrap=1, title='Gmean latency quantile', include_columns=['cgroup', 'quantile'], table_sort=['quantile', 'cgroup'], width=1900, height=1400, gmean_round=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6e3a2b-e96d-4333-8df3-6b2087cdcf4a",
   "metadata": {},
   "source": [
    "# CPU residency - tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c600f-9736-43be-ad71-876685cc5672",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_important = ['RenderThread', 'droid.benchmark', 'surfaceflinger']\n",
    "\n",
    "task_residency_totals = [\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/tasks_residency_total.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/tasks_residency_total.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/tasks_residency_total.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/tasks_residency_total.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/tasks_residency_total.pqt'),\n",
    "]\n",
    "\n",
    "task_residencies = [\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/tasks_residency.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/tasks_residency.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/tasks_residency.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/tasks_residency.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/tasks_residency.pqt'),\n",
    "]\n",
    "\n",
    "cpus = ['0.0', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0']\n",
    "task_residency_total_combined = pd.concat(task_residency_totals).rename(columns={'Total':'total'})\n",
    "task_residency_total_combined['wa_path'] = trim_wa_path(task_residency_total_combined['wa_path'].str)\n",
    "task_residency_total_melt = pd.melt(task_residency_total_combined, id_vars=['iteration', 'wa_path', 'kernel'], value_vars=cpus).rename(columns={'variable':'cluster'})\n",
    "task_residency_total_cluster_melt = pd.melt(task_residency_total_combined, id_vars=['iteration', 'wa_path', 'kernel'], value_vars=clusters_total).rename(columns={'cpu':'cluster'})\n",
    "\n",
    "task_residencies_combined = pd.concat(task_residencies).rename(columns={'Total':'total'}).query(\"comm in @tasks_important\")\n",
    "task_residencies_combined['wa_path'] = trim_wa_path(task_residencies_combined['wa_path'].str)\n",
    "task_residencies_combined_cluster_melt = pd.melt(task_residencies_combined, id_vars=['iteration', 'wa_path', 'kernel', 'comm'], value_vars=clusters_total).rename(columns={'cpu':'cluster'})\n",
    "\n",
    "display(task_residency_total_combined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa43d868-423a-4598-b4b5-f43f54243fbc",
   "metadata": {},
   "source": [
    "## Clusters - Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3effecc2-4b4e-4178-8311-6bbc8de6d594",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hv.Dataset(task_residency_total_cluster_melt, ['iteration', hv.Dimension('wa_path', values=wa_paths), hv.Dimension('cluster', values=clusters_total)], 'value')\n",
    "layout = ds.to(hv.Curve, 'iteration', 'value').overlay('wa_path').opts(legend_position='bottom').layout('cluster').cols(4).opts(title='Mean cluster CPU residency')\n",
    "layout.opts(\n",
    "    opts.Curve(width=600, height=600, ylabel='time'),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5468ec-e29b-4309-8b16-b3809d257e22",
   "metadata": {},
   "source": [
    "## Clusters - Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0093a4-5e2e-4c97-91db-d5aeb5c842bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(task_residency_total_cluster_melt, x='cluster', y='value', facet_col='metric', facet_col_wrap=2, title='Gmean cluster CPU residency', width=1800, height=600, include_columns=['cluster'], order_cluster=True, include_total=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e83da2dd",
   "metadata": {},
   "source": [
    "## Clusters - Per-task bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1980ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_cpu_residency = plot_gmean_bars(task_residencies_combined_cluster_melt, x='cluster', y='value', facet_col='comm', facet_col_wrap=1, title='Gmean cluster task CPU residency', include_columns=['cluster'], width=1800, height=1600, order_cluster=True, include_total=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12134a5-3faa-4720-9ae6-ef941b0c9fa9",
   "metadata": {},
   "source": [
    "## CPUs - Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba7ee15-d37f-4f72-9274-6b0e65f5aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hv.Dataset(task_residency_total_melt, ['iteration', hv.Dimension('wa_path', values=wa_paths), hv.Dimension('cpu', values=cpus)], 'value')\n",
    "layout = ds.to(hv.Curve, 'iteration', 'value').overlay('wa_path').opts(legend_position='bottom').layout('cpu').cols(3).opts(title='Mean CPU residency')\n",
    "layout.opts(\n",
    "    opts.Curve(width=600, height=600, ylabel='time'),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4193b6e-4a0f-4595-af25-52537de4dd7d",
   "metadata": {},
   "source": [
    "## CPUs - Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af2ac4-3586-40e4-8c61-7511fd4b1707",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(task_residency_total_melt, x='cpu', y='value', facet_col='metric', facet_col_wrap=2, title='Gmean CPU residency', include_columns=['cpu'], width=1900, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4849b962-a94c-4e1c-8df7-d3fa835487f1",
   "metadata": {},
   "source": [
    "# CPU residency - cgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff3dcb-df08-4452-b978-c1dd8dc2a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cgroup_residency_totals = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/task_residency_cgroup_total.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/task_residency_cgroup_total.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/task_residency_cgroup_total.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/task_residency_cgroup_total.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/task_residency_cgroup_total.pqt'),\n",
    "    ]\n",
    "    \n",
    "    cpus = ['0.0', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0']\n",
    "    cgroup_residency_total_combined = pd.concat(cgroup_residency_totals).rename(columns={'Total':'total'})[['wa_path', 'cgroup', 'iteration', 'total', 'little', 'mid', 'big', '0.0', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0']]\n",
    "    cgroup_residency_total_combined['wa_path'] = trim_wa_path(cgroup_residency_total_combined['wa_path'].str)\n",
    "    cgroup_residency_total_melt = pd.melt(cgroup_residency_total_combined, id_vars=['iteration', 'wa_path', 'cgroup'], value_vars=cpus).rename(columns={'variable':'cluster'})\n",
    "    cgroup_residency_total_cluster_melt = pd.melt(cgroup_residency_total_combined, id_vars=['iteration', 'wa_path', 'cgroup'], value_vars=clusters_total).rename(columns={'cpu':'cluster'})\n",
    "    \n",
    "    display(cgroup_residency_total_combined)\n",
    "except FileNotFoundError:\n",
    "    print('task_residency_cgroup_total.pqt not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55abe9b3-c4e7-47ba-aea3-c6960d2e48a4",
   "metadata": {},
   "source": [
    "## Clusters - Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a665e4-6d3c-4d90-b84b-1e20acf39ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(cgroup_residency_total_cluster_melt, x='cluster', y='value', facet_col='cgroup', facet_col_wrap=1, title='Gmean cluster CPU residency per-cgroup', width=1800, height=1100, include_columns=['cgroup', 'cluster'], table_sort=['cgroup', 'cluster', 'kernel'], order_cluster=True, include_total=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae2622-f194-45b1-ac9b-70f63c38ba14",
   "metadata": {},
   "source": [
    "## CPUs - Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c91660-6df2-4b10-9239-c59893f5719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(cgroup_residency_total_melt, x='cpu', y='value', facet_col='cgroup', facet_col_wrap=1, title='Gmean cgroup CPU residency', width=1900, height=1200, include_columns=['cgroup', 'cpu'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbcb2636",
   "metadata": {},
   "source": [
    "# Summary - TLDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fdf21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_parts = []\n",
    "\n",
    "try:\n",
    "    summary_mean_durations = mean_durations.copy()\n",
    "    summary_mean_durations['perc_diff'] = summary_mean_durations['perc_diff'].apply(lambda s: f\"({s})\")\n",
    "    summary_mean_durations['value'] = summary_mean_durations['value'] + \" \" + summary_mean_durations['perc_diff']\n",
    "    summary_mean_durations = summary_mean_durations.pivot(values='value', columns='kernel', index='variable').reset_index().rename(columns={'variable':'metric'})[['metric'] + wa_paths]\n",
    "    summary_parts.append(summary_mean_durations)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    summary_jank_percs = jank_percs.copy()\n",
    "    summary_jank_percs['perc_diff'] = summary_jank_percs['perc_diff'].apply(lambda s: f\"({s})\")\n",
    "    summary_jank_percs['value'] = summary_jank_percs['value'] + \" \" + summary_jank_percs['perc_diff']\n",
    "    summary_jank_percs = summary_jank_percs.pivot(values='value', columns='kernel', index='variable').reset_index().rename(columns={'variable':'metric'})[['metric'] + wa_paths]\n",
    "    summary_parts.append(summary_jank_percs)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    summary_max_durations = max_durations.copy()\n",
    "    summary_max_durations = summary_max_durations.pivot(values='value', columns='kernel', index='variable').reset_index().rename(columns={'variable':'metric'})[['metric'] + wa_paths]\n",
    "    summary_parts.append(summary_max_durations)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    summary_power_usage = power_usage.copy().query(\"chan_name == 'total_power'\")\n",
    "    summary_power_usage['perc_diff'] = summary_power_usage['perc_diff'].apply(lambda s: f\"({s})\")\n",
    "    summary_power_usage['value'] = summary_power_usage['value'] + \" \" + summary_power_usage['perc_diff']\n",
    "    summary_power_usage = summary_power_usage.pivot(values='value', columns='kernel', index='chan_name').reset_index().rename(columns={'chan_name':'metric'})[['metric'] + wa_paths]\n",
    "    summary_parts.append(summary_power_usage)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    summary_ou = overutilized_mean.copy()\n",
    "    summary_ou['percentage'] = summary_ou['percentage'].apply(lambda x: f\"{x}%\")\n",
    "    summary_ou = summary_ou.pivot(values='percentage', columns='kernel', index='metric').reset_index()[['metric'] + wa_paths]\n",
    "    summary_parts.append(summary_ou)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    summary_thermal = thermal.copy()\n",
    "    summary_thermal['perc_diff'] = summary_thermal['perc_diff'].apply(lambda s: f\"({s})\")\n",
    "    summary_thermal['value'] = summary_thermal['value'] + \" \" + summary_thermal['perc_diff']\n",
    "    summary_thermal = summary_thermal.pivot(values='value', columns='kernel', index='cluster').reset_index().rename(columns={'cluster':'metric'})[['metric'] + wa_paths]\n",
    "    summary_thermal['metric'] = \"thermal (\" + summary_thermal['metric'] + \")\"\n",
    "    summary_parts.append(summary_thermal)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    summary_wakeup_latency = wakeup_latency.copy()\n",
    "    summary_wakeup_latency['perc_diff'] = summary_wakeup_latency['perc_diff'].apply(lambda s: f\"({s})\")\n",
    "    summary_wakeup_latency['comm'] = \"latency (\" + summary_wakeup_latency['comm'] + \")\"\n",
    "    summary_wakeup_latency['value'] = summary_wakeup_latency['value'] + \" \" + summary_wakeup_latency['perc_diff']\n",
    "    summary_wakeup_latency = summary_wakeup_latency.pivot(values='value', columns='kernel', index='comm').reset_index().rename(columns={'comm':'metric'})[['metric'] + wa_paths]\n",
    "    summary_parts.append(summary_wakeup_latency)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    summary_task_cpu_residency = task_cpu_residency.copy().query(\"cluster == 'total'\")\n",
    "    summary_task_cpu_residency['perc_diff'] = summary_task_cpu_residency['perc_diff'].apply(lambda s: f\"({s})\")\n",
    "    summary_task_cpu_residency['value'] = summary_task_cpu_residency['value'] + \" \" + summary_task_cpu_residency['perc_diff']\n",
    "    summary_task_cpu_residency = summary_task_cpu_residency.pivot(values='value', columns='kernel', index='comm').reset_index().rename(columns={'comm':'metric'})[['metric'] + wa_paths]\n",
    "    summary_task_cpu_residency['metric'] = \"CPU residency (\" + summary_task_cpu_residency['metric'] + \")\"\n",
    "    summary_parts.append(summary_task_cpu_residency)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "summary = pd.concat(summary_parts).reset_index(drop=True)\n",
    "\n",
    "display(summary)\n",
    "print('Jankbench')\n",
    "ptable(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
