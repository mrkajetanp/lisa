{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff00232a-a2be-48c0-8937-abe3a0e99418",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd20c6-2560-4f7a-9df2-c9a1413b7452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from lisa.utils import setup_logging\n",
    "setup_logging(level=logging.CRITICAL)\n",
    "\n",
    "from lisa.trace import Trace\n",
    "from lisa.wa import WAOutput\n",
    "from lisa.stats import Stats\n",
    "from lisa.datautils import series_mean\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "from bokeh.themes import built_in_themes\n",
    "from tabulate import tabulate\n",
    "\n",
    "hv.renderer('bokeh').theme = built_in_themes['dark_minimal']\n",
    "pio.templates.default = \"plotly\"\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "color_cycle = hv.Cycle(['#636EFA', '#EF553B', '#00CC96', '#AB63FA', '#FFA15A', '#19D3F3', '#FF6692', '#B6E880', '#FF97FF', '#FECB52'])\n",
    "\n",
    "opts.defaults(\n",
    "    opts.Curve(tools=['hover'], width=600, height=500, show_grid=True, color=color_cycle, muted_alpha=0),\n",
    "    opts.Table(bgcolor='black')\n",
    ")\n",
    "\n",
    "BENCHMARK_PATH = '/home/kajpuc01/power/pixel6/geekbench/'\n",
    "\n",
    "def trim_number(x):\n",
    "    if x > 1000000000:\n",
    "        return f\"{round(x / 1000000000, 3)}B\"\n",
    "    if x > 1000000:\n",
    "        return f\"{round(x / 1000000, 3)}M\"\n",
    "    if x > 10000:\n",
    "        return f\"{round(x / 1000, 2)}k\"\n",
    "    if x < 0.01:\n",
    "        return f\"{round(x * 1000000, 2)}Î¼\"\n",
    "    return str(x)\n",
    "\n",
    "def format_percentage(vals, perc, pvals, pval_threshold=0.02):\n",
    "    result = round(perc, 2).astype(str).apply(lambda s: f\"({'' if s.startswith('-') or (s == '0.0') else '+'}{s}%)\").to_frame()\n",
    "    result['vals'] = vals.apply(lambda x: trim_number(x))\n",
    "    result['pvals'] = pvals\n",
    "    result['pval_marker'] = pvals.apply(lambda x: \"* \" if x < pval_threshold else \"\")\n",
    "    result['value'] = result['vals'] + \" \" + result['pval_marker'] + result['value']\n",
    "    return result['value']\n",
    "\n",
    "def plot_gmean_bars(df, x='stat', y='value', facet_col='metric', facet_col_wrap=3, title='', width=800, height=600, gmean_round=1, include_columns=[], table_sort=None, order_cluster=False, sort_ascending=False, include_total=False, debug=False):\n",
    "    shown_clusters = clusters if not include_total else clusters_total\n",
    "    \n",
    "    if not 'unit' in df.columns:\n",
    "        df['unit'] = 'x'\n",
    "    if not 'metric' in df.columns:\n",
    "        df['metric'] = 'gmean'\n",
    "        \n",
    "    if debug:\n",
    "        print('df')\n",
    "        display(df)\n",
    "        \n",
    "        \n",
    "    # compute percentage differences\n",
    "    stats_perc = Stats(df, ref_group={'wa_path': a_wa_path}, value_col=y, agg_cols=['iteration'], stats={'gmean': sp.stats.gmean}).df\n",
    "    # re-add stub a_wa_path\n",
    "    stats_perc_values_temp = stats_perc.query(\"wa_path == @b_wa_path\")\n",
    "    stats_perc_values_temp['wa_path'] = a_wa_path\n",
    "    stats_perc_values_temp['value'] = 0\n",
    "    # re-combine a df with percentage differences\n",
    "    stats_perc_values = pd.concat([stats_perc_values_temp, stats_perc])\n",
    "    stats_perc_values['order_kernel'] = stats_perc_values['wa_path'].map(lambda x: wa_paths.index(x))\n",
    "    \n",
    "    if debug:\n",
    "        print('stats_perc_values')\n",
    "        display(stats_perc_values)\n",
    "    \n",
    "    sort_list = ['metric']\n",
    "    \n",
    "    if order_cluster:\n",
    "        sort_list.append('order_cluster')\n",
    "        stats_perc_values['order_cluster'] = stats_perc_values['cluster'].map(lambda x: shown_clusters.index(x))\n",
    "        \n",
    "    sort_list.append('order_kernel')\n",
    "\n",
    "    # split into dfs with percentages and pvalues\n",
    "    stats_perc_pvalues = stats_perc_values.query(\"stat == 'ks2samp_test'\").sort_values(by=sort_list).reset_index(drop=True)\n",
    "    stats_perc_values = stats_perc_values.query(\"stat == 'gmean'\").sort_values(by=sort_list).reset_index(drop=True)\n",
    "\n",
    "    # compute absolute gmeans\n",
    "    gmeans = Stats(df, agg_cols=['iteration'], stats={'gmean': sp.stats.gmean, 'std': None, 'sem': None}).df\n",
    "    if gmean_round > 0:\n",
    "        gmeans['value'] = round(gmeans['value'], gmean_round)\n",
    "    gmeans['order_kernel'] = gmeans['wa_path'].map(lambda x: wa_paths.index(x))\n",
    "    \n",
    "    if order_cluster:\n",
    "        gmeans['order_cluster'] = gmeans['cluster'].map(lambda x: shown_clusters.index(x))\n",
    "        \n",
    "    if debug:\n",
    "        display(stats_perc_pvalues)\n",
    "\n",
    "    gmeans_mean = gmeans.query(\"stat == 'gmean'\").sort_values(by=sort_list).reset_index(drop=True)\n",
    "    if debug:\n",
    "        print(sort_list)\n",
    "        print('gmeans')\n",
    "        display(gmeans)\n",
    "        \n",
    "    data_table_cols = [col for col in gmeans_mean.columns if col in (['wa_path', 'value', 'test_name', 'variable', 'metric', 'chan_name', 'comm'] + include_columns)]\n",
    "    data_table = gmeans_mean[data_table_cols].rename(columns={'wa_path':'kernel'})\n",
    "    data_table['perc_diff'] = stats_perc_values['value'].map(lambda x: str(round(x, 2)) + '%')\n",
    "    data_table['value'] = data_table['value'].apply(lambda x: trim_number(x))\n",
    "    if table_sort is not None:\n",
    "        data_table = data_table.sort_values(by=table_sort)\n",
    "    ptable(data_table)\n",
    "        \n",
    "    # plot bars\n",
    "    fig = px.bar(gmeans_mean, x=x, y=y, color='wa_path', facet_col=facet_col, facet_col_wrap=facet_col_wrap, barmode='group', text=format_percentage(gmeans_mean['value'], stats_perc_values['value'], stats_perc_pvalues['value']), title=title, width=width, height=height)\n",
    "    fig.update_traces(textposition='outside')\n",
    "    fig.update_yaxes(matches=None)\n",
    "    if sort_ascending:\n",
    "        fig.update_xaxes(categoryorder='total ascending')\n",
    "    fig.show()\n",
    "\n",
    "    return data_table\n",
    "    \n",
    "def ptable(df):\n",
    "    print(tabulate(df, headers='keys', tablefmt='pretty', showindex=False, floatfmt=\".3f\"))\n",
    "\n",
    "def trim_wa_path(path):\n",
    "    return path[10:-7]\n",
    "    #return path[10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e20065-b59c-4d93-9fc2-d828c929f174",
   "metadata": {},
   "source": [
    "## Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10a2149-063b-41e2-b974-8ee64d8d9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_name_a = 'geekbench_baseline_3_0812'\n",
    "benchmark_name_b = 'geekbench_eas_lock_3_1301'\n",
    "benchmark_name_c = 'geekbench_ufc_patched_v4_3_2001'\n",
    "benchmark_name_d = 'geekbench_ufc_feec_all_cpus_3_3001'\n",
    "benchmark_name_e = 'geekbench_ufc_feec_all_cpus_fits_3_3001'\n",
    "\n",
    "wa_output_a = WAOutput(BENCHMARK_PATH + benchmark_name_a)\n",
    "wa_output_b = WAOutput(BENCHMARK_PATH + benchmark_name_b)\n",
    "wa_output_c = WAOutput(BENCHMARK_PATH + benchmark_name_c)\n",
    "wa_output_d = WAOutput(BENCHMARK_PATH + benchmark_name_d)\n",
    "wa_output_e = WAOutput(BENCHMARK_PATH + benchmark_name_e)\n",
    "\n",
    "df_a = wa_output_a['results'].df\n",
    "df_b = wa_output_b['results'].df\n",
    "df_c = wa_output_c['results'].df\n",
    "df_d = wa_output_d['results'].df\n",
    "df_e = wa_output_e['results'].df\n",
    "\n",
    "a_kernel = df_a['kernel'][0]\n",
    "b_kernel = df_b['kernel'][0]\n",
    "c_kernel = df_c['kernel'][0]\n",
    "d_kernel = df_d['kernel'][0]\n",
    "e_kernel = df_e['kernel'][0]\n",
    "\n",
    "a_wa_path = trim_wa_path(df_a['wa_path'][0])\n",
    "b_wa_path = trim_wa_path(df_b['wa_path'][0])\n",
    "c_wa_path = trim_wa_path(df_c['wa_path'][0])\n",
    "d_wa_path = trim_wa_path(df_d['wa_path'][0])\n",
    "e_wa_path = trim_wa_path(df_e['wa_path'][0])\n",
    "wa_paths = [a_wa_path, b_wa_path, c_wa_path, d_wa_path, e_wa_path]\n",
    "\n",
    "df = pd.concat([df_a, df_b, df_c, df_d, df_e])\n",
    "df = df.drop(columns=['scaled from(%)'])\n",
    "df['wa_path'] = trim_wa_path(df['wa_path'].str)\n",
    "df_perf = df[df['metric'].str.contains('perf')].reset_index(drop=True).query(\"value != 0\")\n",
    "df_perf['metric'] = df_perf['metric'].str[7:]\n",
    "df = df[~df['metric'].str.contains('perf')].reset_index(drop=True).query(\"value != 0\")\n",
    "\n",
    "clusters = ['little', 'mid', 'big']\n",
    "clusters_total = ['little', 'mid', 'big', 'total']\n",
    "\n",
    "print(benchmark_name_a, benchmark_name_b, benchmark_name_c, benchmark_name_d, benchmark_name_e)\n",
    "\n",
    "print(wa_paths)\n",
    "print(a_kernel, b_kernel, c_kernel, d_kernel, e_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f367aadf-d0db-46a7-a147-246d17358d65",
   "metadata": {},
   "source": [
    "# Benchmark scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f67f101-e3b1-49c2-8628-b739d90a1785",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bcdb31-01dd-46bf-ab44-fb545c218bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['multicore_score', 'score']\n",
    "ds = hv.Dataset(df, ['iteration', hv.Dimension('wa_path', values=wa_paths), hv.Dimension('metric', values=metrics)], 'value')\n",
    "layout = ds.select(metric=metrics).to(hv.Curve, 'iteration', 'value').overlay('wa_path').opts(legend_position='bottom').layout('metric').opts(shared_axes=False, title='Benchmark score per-iteration').cols(2)\n",
    "layout.opts(\n",
    "    opts.Curve(height=600, width=900),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0767de4-b599-4321-aedb-c335d9ac730b",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e166d27b-6b76-40d8-b5b4-f382f3bed602",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_scores = plot_gmean_bars(df.query(\"metric in @metrics\"), x='stat', y='value', facet_col='metric', facet_col_wrap=3, title='gmean score', width=1600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecb4da7-16cf-4c35-8668-319b2dcaa66a",
   "metadata": {},
   "source": [
    "# Overutilized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b492af58-8fbc-4043-b0ef-5b2eaa3ada80",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    overutils = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/overutilized.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/overutilized.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/overutilized.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/overutilized.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/overutilized.pqt'),\n",
    "    ]\n",
    "\n",
    "    overutilized_combined = pd.concat(overutils)\n",
    "    overutilized_combined['wa_path'] = trim_wa_path(overutilized_combined['wa_path'].str)\n",
    "    overutilized_combined['time'] = round(overutilized_combined['time'], 2)\n",
    "    overutilized_combined['total_time'] = round(overutilized_combined['total_time'], 2)\n",
    "    \n",
    "    overutilized_mean = overutilized_combined.groupby(['wa_path']).agg(lambda x: series_mean(x)).reset_index().rename(columns={'wa_path':'kernel'})\n",
    "    overutilized_mean['metric'] = 'overutilized'\n",
    "    overutilized_mean = overutilized_mean[['metric', 'kernel', 'time', 'total_time', 'percentage']]\n",
    "    overutilized_mean['percentage'] = round(overutilized_mean['percentage'], 2)\n",
    "    overutilized_mean['time'] = round(overutilized_mean['time'], 2)\n",
    "    overutilized_mean['total_time'] = round(overutilized_mean['total_time'], 2)\n",
    "    ptable(overutilized_mean)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print('overutilized.pqt not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f1996-cf18-401d-b0c3-176a55d84ab7",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5469cac-4b20-4e49-9d86-84a8bbe20191",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(overutilized_combined, x='iteration', y='percentage', color='wa_path', height=600, title='Overutilized percentage per-iteration')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41063ef2-6933-4a5f-9a4d-3c2102e2b051",
   "metadata": {},
   "source": [
    "# Perf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eaab41-98e1-4510-8104-afdab8d7ea89",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76015fad-1b2c-42b3-b51a-ef3fa2e213fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['cpu-migrations', 'context-switches', 'stalled-cycles-backend', 'page-faults', 'major-faults', 'cache-misses', 'instructions', 'cpu-cycles', 'cpu-clock']\n",
    "ds = hv.Dataset(df_perf, ['iteration', hv.Dimension('wa_path', values=wa_paths), hv.Dimension('metric', values=metrics)], 'value')\n",
    "layout = ds.select(metric=metrics).to(hv.Curve, 'iteration', 'value').overlay('wa_path').opts(legend_position='bottom').layout('metric').opts(shared_axes=False, title='Perf counters').cols(3)\n",
    "layout.opts(\n",
    "    opts.Curve(width=600, height=340),\n",
    "    opts.Overlay(legend_position='bottom'),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27799672-3e88-4d8f-872a-744661ac5fde",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e024f-4504-4243-bd80-77ae9412d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['cpu-migrations', 'context-switches', 'stalled-cycles-backend', 'page-faults', 'major-faults', 'minor-faults', 'cache-misses', 'instructions', 'cpu-cycles', 'cpu-clock']\n",
    "plot_gmean_bars(df_perf.query(\"metric in @metrics\"), x='stat', y='value', facet_col='metric', facet_col_wrap=5, title='gmean perf counters', width=1900, height=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d8f0fb-a413-47eb-8fcf-e026f976d67c",
   "metadata": {},
   "source": [
    "# Idle residency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc982f-a400-4a41-aedf-dcf5565ac62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    idle_residency_times_a = pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/idle_residency.pqt')\n",
    "    idle_residency_times_b = pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/idle_residency.pqt')\n",
    "    idle_residency_times_c = pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/idle_residency.pqt')\n",
    "    idle_residency_times_d = pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/idle_residency.pqt')\n",
    "    \n",
    "    idle_residency_times_combined = pd.concat([idle_residency_times_a, idle_residency_times_b, idle_residency_times_c, idle_residency_times_d])\n",
    "    idle_residency_times_combined['wa_path'] = trim_wa_path(idle_residency_times_combined['wa_path'].str)\n",
    "    \n",
    "    display(idle_residency_times_combined)\n",
    "except FileNotFoundError:\n",
    "    print('idle_residency.pqt not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9265a2af-4f08-4767-8c36-4cc794d50d4a",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f46686-8970-4799-b7f0-af4b5ccefd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "residency_data = idle_residency_times_combined.groupby(['wa_path', 'cluster', 'idle_state'], sort=False).mean().reset_index()[['wa_path', 'cluster', 'idle_state', 'time']]\n",
    "residency_data['time'] = round(residency_data['time'], 2)\n",
    "\n",
    "fig = px.bar(residency_data, x='idle_state', y='time', color='wa_path', facet_col='cluster', barmode='group', text=residency_data['time'],\n",
    "             width=1800, height=600, title='Idle state residencies')\n",
    "fig.update_traces(textposition='outside')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0e4a6-30a9-42fd-bfad-5f4da92e96b8",
   "metadata": {},
   "source": [
    "# Idle misses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7652f5b4-4c0e-4177-8ecc-35269153f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cpu_idle_a = pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/cpu_idle.pqt')\n",
    "    cpu_idle_b = pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/cpu_idle.pqt')\n",
    "    cpu_idle_c = pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/cpu_idle.pqt')\n",
    "    cpu_idle_d = pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/cpu_idle.pqt')\n",
    "    cpu_idle_a_wakeups = len(cpu_idle_a.query(\"state == 4294967295\"))\n",
    "    cpu_idle_b_wakeups = len(cpu_idle_b.query(\"state == 4294967295\"))\n",
    "    cpu_idle_c_wakeups = len(cpu_idle_c.query(\"state == 4294967295\"))\n",
    "    cpu_idle_d_wakeups = len(cpu_idle_d.query(\"state == 4294967295\"))\n",
    "except FileNotFoundError:\n",
    "    print('cpu_idle.pqt not found.')\n",
    "\n",
    "try:\n",
    "    cpu_idle_miss_a = pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/cpu_idle_miss_counts.pqt')\n",
    "    cpu_idle_miss_a['count_perc'] = round(cpu_idle_miss_a['count'] / cpu_idle_a_wakeups * 100, 3)\n",
    "    cpu_idle_miss_b = pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/cpu_idle_miss_counts.pqt')\n",
    "    cpu_idle_miss_b['count_perc'] = round(cpu_idle_miss_b['count'] / cpu_idle_b_wakeups * 100, 3)\n",
    "    cpu_idle_miss_c = pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/cpu_idle_miss_counts.pqt')\n",
    "    cpu_idle_miss_c['count_perc'] = round(cpu_idle_miss_c['count'] / cpu_idle_c_wakeups * 100, 3)\n",
    "    cpu_idle_miss_d = pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/cpu_idle_miss_counts.pqt')\n",
    "    cpu_idle_miss_d['count_perc'] = round(cpu_idle_miss_d['count'] / cpu_idle_d_wakeups * 100, 3)\n",
    "    \n",
    "    cpu_idle_miss_combined = pd.concat([cpu_idle_miss_a, cpu_idle_miss_b, cpu_idle_miss_c, cpu_idle_miss_d])\n",
    "    cpu_idle_miss_combined['type'] = cpu_idle_miss_combined['below'].replace(0, 'too deep').replace(1, 'too shallow')\n",
    "    cpu_idle_miss_combined['wa_path'] = cpu_idle_miss_combined['wa_path'].str[10:-7]\n",
    "    \n",
    "    display(cpu_idle_miss_combined)\n",
    "    \n",
    "    a_miss_percentage = round(cpu_idle_miss_a['count'].sum() / cpu_idle_a_wakeups * 100, 3)\n",
    "    b_miss_percentage = round(cpu_idle_miss_b['count'].sum() / cpu_idle_b_wakeups * 100, 3)\n",
    "    c_miss_percentage = round(cpu_idle_miss_c['count'].sum() / cpu_idle_c_wakeups * 100, 3)\n",
    "    d_miss_percentage = round(cpu_idle_miss_d['count'].sum() / cpu_idle_d_wakeups * 100, 3)\n",
    "    print(f\"{a_miss_percentage}% {a_wa_path} vs {b_miss_percentage}% {b_wa_path}\")\n",
    "    print(f\"{c_miss_percentage}% {c_wa_path} vs {d_miss_percentage}% {d_wa_path}\")\n",
    "except FileNotFoundError:\n",
    "    print('cpu_idle_miss_counts.pqt not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ced96e-cbf0-448e-b653-82743e086979",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptable(cpu_idle_miss_combined.groupby(['wa_path', 'type']).sum().reset_index()[['wa_path', 'type', 'count_perc']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85154dbd-7e6d-42e5-ab77-ca8bf244d810",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad450e7-4f26-4ee6-be9c-c2b33707b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(cpu_idle_miss_combined, x='type', y='count_perc', color='wa_path', facet_col='cluster', barmode='group', text=cpu_idle_miss_combined['count_perc'], width=1800, height=600, title='CPUIdle misses as percentage of all wakeups')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef18dfd4-9020-4666-8cb9-55021e206840",
   "metadata": {},
   "source": [
    "# Power usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03562334-977f-4f5e-ae5a-4c88d9767b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pixel6_emeters = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/pixel6_emeter.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/pixel6_emeter.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/pixel6_emeter.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/pixel6_emeter.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/pixel6_emeter.pqt'),\n",
    "    ]\n",
    "    \n",
    "    pixel6_emeter_means = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/pixel6_emeter_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/pixel6_emeter_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/pixel6_emeter_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/pixel6_emeter_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/pixel6_emeter_mean.pqt'),\n",
    "    ]\n",
    "    \n",
    "    pixel6_emeters_combined = pd.concat(pixel6_emeters)\n",
    "    pixel6_emeters_combined['wa_path'] = trim_wa_path(pixel6_emeters_combined['wa_path'].str)\n",
    "    pixel6_emeter_means_combined = pd.concat(pixel6_emeter_means)\n",
    "    pixel6_emeter_means_combined['total_power'] = pixel6_emeter_means_combined[['little_power', 'mid_power', 'big_power']].sum(axis=1)\n",
    "    pixel6_emeter_means_combined['wa_path'] = trim_wa_path(pixel6_emeter_means_combined['wa_path'].str)\n",
    "    \n",
    "    pixel6_emeter_melt = pd.melt(pixel6_emeter_means_combined, id_vars=['iteration', 'wa_path', 'kernel'], value_vars=['little_power', 'mid_power', 'big_power', 'total_power'])\n",
    "    pixel6_emeter_melt['cluster'] = pixel6_emeter_melt['chan_name'].str[:-6]\n",
    "except FileNotFoundError:\n",
    "    print('pixel6_emeter.pqt not found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b9c9fe-8298-4b6e-a0d5-0d068a7be79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel6_emeters_combined.groupby(['wa_path', 'iteration']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6618dc-34d2-4f55-937a-0644ad9424ae",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1b971-a771-47ac-bc3c-c23b4dda5fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(pixel6_emeter_melt, x='iteration', y='value', color='wa_path', facet_col='cluster', height=600, title='Mean power usage across iterations [mW]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5eb606-bc8e-4b3e-8bab-2e11eb28d6e4",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a2de01-0fee-4f19-ba49-aa99c3e59430",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_usage = plot_gmean_bars(pixel6_emeter_melt, x='chan_name', y='value', facet_col='metric', facet_col_wrap=5, title='Gmean power usage [mW]', width=1800, height=600, order_cluster=True, include_total=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aa9c3b-0b24-44ca-83f0-5937eefd4cb1",
   "metadata": {},
   "source": [
    "# Energy estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850b279-bb0a-4fed-920e-16ac797e0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    energy_estimate_means = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/energy_estimate_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/energy_estimate_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/energy_estimate_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/energy_estimate_mean.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/energy_estimate_mean.pqt'),\n",
    "    ]\n",
    "    \n",
    "    energy_estimate_means_combined = pd.concat(energy_estimate_means)\n",
    "    energy_estimate_means_combined['wa_path'] = energy_estimate_means_combined['wa_path'].str[20:-7]\n",
    "    energy_estimate_melt = pd.melt(energy_estimate_means_combined, id_vars=['iteration', 'wa_path'], value_vars=['little', 'mid', 'big', 'total']).rename(columns={'variable':'cluster'})\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print('energy_estimate_mean.pqt not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1f40fd-4b60-45bb-80be-5b6424d6dce7",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c9526d-9c13-4dd2-bfbf-dd016c38740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(energy_estimate_melt, x='iteration', y='value', color='wa_path', facet_col='cluster', height=600, title='Mean energy estimate across iterations [bW]')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c3cec1-d721-4c3c-a3a3-310be70ea641",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0543d5b9-a7f1-4fdf-94b7-6c4301860df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_estimate = plot_gmean_bars(energy_estimate_melt, x='cluster', y='value', facet_col='metric', facet_col_wrap=5, title='Gmean energy estimate [bW]', width=1900, height=600, include_columns=['cluster'], order_cluster=True, include_total=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c462a9-a006-4d33-81e7-0b63325c75c4",
   "metadata": {},
   "source": [
    "# Thermal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca56d6f-a22f-47ba-bb3b-90299c5cd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    thermals = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/thermal.pqt').groupby(['iteration', 'kernel', 'wa_path']).agg(lambda x: series_mean(x)).reset_index(),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/thermal.pqt').groupby(['iteration', 'kernel', 'wa_path']).agg(lambda x: series_mean(x)).reset_index(),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/thermal.pqt').groupby(['iteration', 'kernel', 'wa_path']).agg(lambda x: series_mean(x)).reset_index(),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/thermal.pqt').groupby(['iteration', 'kernel', 'wa_path']).agg(lambda x: series_mean(x)).reset_index(),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/thermal.pqt').groupby(['iteration', 'kernel', 'wa_path']).agg(lambda x: series_mean(x)).reset_index()\n",
    "    ]\n",
    "    \n",
    "    for i in range(len(thermals)):\n",
    "        for col in [c for c in thermals[i].columns if c not in ['time', 'iteration', 'kernel', 'wa_path']]:\n",
    "            thermals[i][col] = thermals[i][col] / 1000\n",
    "        thermals[i] = round(thermals[i], 2)\n",
    "        thermals[i]['wa_path'] = thermals[i]['wa_path'].str[20:-7]\n",
    "\n",
    "    thermal_combined = pd.concat(thermals)\n",
    "    thermal_melt = pd.melt(thermal_combined, id_vars=['iteration', 'wa_path', 'kernel'], value_vars=['little', 'mid', 'big']).rename(columns={'variable':'cluster'})\n",
    "except FileNotFoundError:\n",
    "    print('thermal.pqt not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0efab5b-80b0-4e5a-a076-b62a1508a492",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11d42f-6073-486b-98ab-658d0104f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hv.Dataset(thermal_melt, ['iteration', hv.Dimension('wa_path', values=wa_paths), hv.Dimension('cluster', values=clusters)], 'value')\n",
    "layout = ds.to(hv.Curve, 'iteration', 'value').overlay('wa_path').opts(legend_position='bottom').layout('cluster').opts(title='Mean cluster temperature across iterations')\n",
    "layout.opts(\n",
    "    opts.Curve(width=600, height=600, ylabel='temperature'),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f266d7a-2386-445f-8987-d0baaefb3a5b",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71afecc5-68f5-429e-b9b8-f359a9aebfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "thermal = plot_gmean_bars(thermal_melt, x='cluster', y='value', facet_col='metric', facet_col_wrap=2, title='Gmean temperature', width=1800, height=600, order_cluster=True, include_columns=['cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc02cb0-0bcc-4367-bc37-8120108ec70e",
   "metadata": {},
   "source": [
    "# Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e5880b-88c0-424e-94f5-2635a26884e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_means = [\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/freqs_mean.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/freqs_mean.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/freqs_mean.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/freqs_mean.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/freqs_mean.pqt'),\n",
    "]\n",
    "    \n",
    "freqs_mean_combined = pd.concat(freqs_means)\n",
    "freqs_mean_combined['wa_path'] = trim_wa_path(freqs_mean_combined['wa_path'].str)\n",
    "freqs_mean_combined['unit'] = 'MHz'\n",
    "freqs_mean_combined['metric'] = 'frequency'\n",
    "\n",
    "freqs_mean_combined['order'] = freqs_mean_combined['cluster'].replace('little', 0).replace('mid', 1).replace('big', 2)\n",
    "freqs_mean_combined = freqs_mean_combined.sort_values(by=['iteration', 'order']).rename(columns={'frequency':'value'})\n",
    "\n",
    "display(freqs_mean_combined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d1e3ef-7665-4b99-b3b8-3c8bec6dc4b7",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca933d3-916d-4656-9613-9aa991b708f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hv.Dataset(freqs_mean_combined, ['iteration', hv.Dimension('wa_path', values=wa_paths), hv.Dimension('cluster', values=clusters)], 'value')\n",
    "layout = ds.to(hv.Curve, 'iteration', 'value').overlay('wa_path').opts(legend_position='bottom').layout('cluster').opts(title='Mean cluster frequency across iterations')\n",
    "layout.opts(\n",
    "    opts.Curve(width=600, height=600, ylabel='MHz'),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e2bc5-5ddc-4627-850d-e5e27b683e53",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb72d9b-f40f-4428-a8bd-0cd2e19d7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = plot_gmean_bars(freqs_mean_combined, x='metric', y='value', facet_col='cluster', facet_col_wrap=3, title='Gmean frequency per cluster', width=1800, height=600, order_cluster=True, include_columns=['cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93c6cb7-86e9-4a3d-afa0-792aa953c70f",
   "metadata": {},
   "source": [
    "# CFS signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0814340a-e6bf-4356-964e-6fa341c17842",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs_signals = [\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/sched_pelt_cfs_mean.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/sched_pelt_cfs_mean.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/sched_pelt_cfs_mean.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/sched_pelt_cfs_mean.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/sched_pelt_cfs_mean.pqt'),\n",
    "]\n",
    "\n",
    "cfs_signals_combined = pd.concat(cfs_signals)\n",
    "cfs_signals_combined['wa_path'] = trim_wa_path(cfs_signals_combined['wa_path'].str)\n",
    "cfs_signals_combined['kernel'] = 'android-mainline-5.18'\n",
    "cfs_signals_melt = pd.melt(cfs_signals_combined, id_vars=['iteration', 'wa_path', 'kernel', 'cluster'], value_vars=['util', 'load'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b528221-8603-4227-9493-d5062d9c18ef",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5bb4c6-fc80-47ac-ad0c-2af15505b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = ['util', 'load']\n",
    "ds = hv.Dataset(cfs_signals_combined, ['iteration', hv.Dimension('wa_path', values=wa_paths), hv.Dimension('cluster', values=clusters)], signals)\n",
    "layout = hv.Layout([ds.to(hv.Curve, 'iteration', signal).overlay('wa_path').opts(legend_position='bottom').layout('cluster').opts(title='Mean cluster ' + signal) for signal in signals]).cols(1)\n",
    "layout.opts(\n",
    "    opts.Curve(width=800, height=400),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f95971-59c6-45d4-9895-937c42fb082c",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc087f-c2a2-4061-835f-eeeda2e757c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs_signals = plot_gmean_bars(cfs_signals_melt, x='cluster', y='value', facet_col='variable', facet_col_wrap=1, title='Gmean cfs signals', width=1900, height=1000, order_cluster=True, include_columns=['cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888beb4e-4dff-459b-b859-edcb9d1e7c70",
   "metadata": {},
   "source": [
    "# Task wakeup latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d60cf-e9c9-42d2-b1b4-d880057e94bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wakeup_latency_means = [\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/wakeup_latency_mean.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/wakeup_latency_mean.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/wakeup_latency_mean.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/wakeup_latency_mean.pqt'),\n",
    "    pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/wakeup_latency_mean.pqt'),\n",
    "]\n",
    "\n",
    "wakeup_latency_mean_combined = pd.concat(wakeup_latency_means).rename(columns={'wakeup_latency':'value'})\n",
    "wakeup_latency_mean_combined['wa_path'] = trim_wa_path(wakeup_latency_mean_combined['wa_path'].str)\n",
    "wakeup_latency_mean_combined['order'] = wakeup_latency_mean_combined['wa_path'].map(lambda x: wa_paths.index(x))\n",
    "wakeup_latency_mean_combined['unit'] = 'x'\n",
    "\n",
    "wakeup_latencies = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/wakeup_latency.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/wakeup_latency.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/wakeup_latency.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/wakeup_latency.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/wakeup_latency.pqt'),\n",
    "]\n",
    "    \n",
    "wakeup_latency_combined = pd.concat(wakeup_latencies)\n",
    "wakeup_latency_combined['wa_path'] = trim_wa_path(wakeup_latency_combined['wa_path'].str)\n",
    "wakeup_latency_combined['order'] = wakeup_latency_combined['wa_path'].map(lambda x: wa_paths.index(x))\n",
    "wakeup_latency_combined['cluster'] = wakeup_latency_combined['cpu'].copy().apply(lambda c: 'little' if c < 4 else 'big' if c > 5 else 'mid')\n",
    "wakeup_latency_combined['order_cluster'] = wakeup_latency_combined['cluster'].map(lambda x: clusters.index(x))\n",
    "wakeup_latency_combined['target_cluster'] = wakeup_latency_combined['target_cpu'].copy().apply(lambda c: 'little' if c < 4 else 'big' if c > 5 else 'mid')\n",
    "wakeup_latency_combined['order_target_cluster'] = wakeup_latency_combined['target_cluster'].map(lambda x: clusters.index(x))\n",
    "wakeup_latency_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917600bb-5af9-4450-9c1d-54b2f3234ff5",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58193a2-e34c-4ed6-87a6-0c18269a8d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(wakeup_latency_mean_combined, x='iteration', y='value', color='wa_path', facet_col='comm', facet_col_wrap=3, height=600, title='Task wakeup latencies across iterations')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8520262-13e3-41e7-bcf1-e11d6809171f",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98746075-e7c0-4f43-a4ab-4bc7d621799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wakeup_latency = plot_gmean_bars(wakeup_latency_mean_combined, x='metric', y='value', facet_col='comm', facet_col_wrap=3, title='Gmean task wakeup latency', table_sort=['comm', 'kernel'], gmean_round=0, width=1900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0469ac47-0916-4c39-8cb4-3adbd3cf15f4",
   "metadata": {},
   "source": [
    "## Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce0019b-da08-495e-a8a2-86d340ff8ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wakeup_latency_quantiles = wakeup_latency_combined.groupby(['comm', 'wa_path', 'iteration']).quantile([0.9, 0.95, 0.99]).reset_index()[['comm', 'wa_path', 'level_3', 'iteration', 'wakeup_latency', 'order']].rename(columns={'level_3':'quantile'}).sort_values(by=['comm', 'order'])\n",
    "wakeup_latency_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284bc498-67ab-451d-be44-1b47a496fc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(wakeup_latency_quantiles.rename(columns={'wakeup_latency':'value'}), x='quantile', y='value', facet_col='comm', facet_col_wrap=1, title='Gmean latency quantile', width=1900, include_columns=['quantile'], table_sort=['quantile', 'comm'], height=1000, gmean_round=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68d6aabf",
   "metadata": {},
   "source": [
    "## Per-execution cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_cluster = wakeup_latency_combined.groupby(['comm', 'wa_path', 'cluster']).mean().reset_index().sort_values(by=['comm', 'order_cluster', 'order'])[['comm', 'wa_path', 'cluster', 'wakeup_latency']]\n",
    "fig = px.bar(latency_cluster, x='cluster', y='wakeup_latency', color='wa_path', facet_col='comm', barmode='group', facet_col_wrap=1, width=2000, height=1300, text=latency_cluster['wakeup_latency'].apply(lambda x: trim_number(x)), title='Mean task wakeup latency per cluster')\n",
    "fig.update_traces(textposition='outside')\n",
    "latency_cluster['wakeup_latency'] = latency_cluster['wakeup_latency'].apply(lambda x: trim_number(x))\n",
    "ptable(latency_cluster)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb98456c",
   "metadata": {},
   "source": [
    "## Per-target cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb6af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency_target_cluster = wakeup_latency_combined.groupby(['comm', 'wa_path', 'target_cluster']).mean().reset_index().sort_values(by=['comm', 'order_target_cluster', 'order'])[['comm', 'wa_path', 'target_cluster', 'wakeup_latency']]\n",
    "fig = px.bar(latency_target_cluster, x='target_cluster', y='wakeup_latency', color='wa_path', facet_col='comm', barmode='group', facet_col_wrap=1, width=2000, height=1300, text=latency_target_cluster['wakeup_latency'].apply(lambda x: trim_number(x)), title='Mean task wakeup latency per target_cluster')\n",
    "fig.update_traces(textposition='outside')\n",
    "latency_target_cluster['wakeup_latency'] = latency_target_cluster['wakeup_latency'].apply(lambda x: trim_number(x))\n",
    "ptable(latency_target_cluster)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116375c2-c0c6-43bc-8ea2-3ab849ec281a",
   "metadata": {},
   "source": [
    "# Wakeup latency - cgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d73ed7-0f03-48b8-b16a-ef7be86d2868",
   "metadata": {},
   "outputs": [],
   "source": [
    "wakeup_latencies_cgroup = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/wakeup_latency_cgroup.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/wakeup_latency_cgroup.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/wakeup_latency_cgroup.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/wakeup_latency_cgroup.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/wakeup_latency_cgroup.pqt'),\n",
    "]\n",
    "\n",
    "wakeup_latency_cgroup_combined = pd.concat(wakeup_latencies_cgroup).rename(columns={'wakeup_latency':'value'})\n",
    "wakeup_latency_cgroup_combined['wa_path'] = trim_wa_path(wakeup_latency_cgroup_combined['wa_path'].str)\n",
    "wakeup_latency_cgroup_combined['order'] = wakeup_latency_cgroup_combined['wa_path'].map(lambda x: wa_paths.index(x))\n",
    "\n",
    "wakeup_latency_cgroup_mean = wakeup_latency_cgroup_combined.groupby([\"wa_path\", \"cgroup\", \"iteration\", \"order\"]).agg(lambda x: series_mean(x)).reset_index().sort_values(by=[\"order\", \"cgroup\", \"iteration\"])[['wa_path', 'cgroup', 'iteration', 'value', 'order']]\n",
    "wakeup_latency_cgroup_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67518df6-c106-46dd-b0e9-051393cbfd6c",
   "metadata": {},
   "source": [
    "## Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a13531-73ee-4155-a0bf-6a61d3754266",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(wakeup_latency_cgroup_mean, x='iteration', y='value', color='wa_path', facet_col='cgroup', facet_col_wrap=3, height=600, title='cgroup wakeup latencies across iterations')\n",
    "fig.update_yaxes(matches=None)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7af694-a003-45e4-b4b2-6fafa5026d97",
   "metadata": {},
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d71039-34ff-47a2-b85e-f28a130f64a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(wakeup_latency_cgroup_mean, x='metric', y='value', facet_col='cgroup', title='Gmean task wakeup latency per-cgroup', include_columns=['cgroup'], table_sort=['cgroup'], gmean_round=0, width=1800, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902559ca-d039-45e3-9dec-b956c6815e52",
   "metadata": {},
   "source": [
    "## Quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350904b3-caa0-4c31-9049-a8fc281cfafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wakeup_latency_cgroup_quantiles = wakeup_latency_cgroup_mean.groupby(['cgroup', 'wa_path', 'iteration']).quantile([0.9, 0.95, 0.99]).reset_index()[['cgroup', 'wa_path', 'level_3', 'iteration', 'value', 'order']].rename(columns={'level_3':'quantile'}).sort_values(by=['cgroup', 'order'])\n",
    "wakeup_latency_cgroup_quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd1a66a-d35f-4109-9be0-51ebc5f17620",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(wakeup_latency_cgroup_quantiles, x='quantile', y='value', facet_col='cgroup', facet_col_wrap=1, title='Gmean latency quantile per-cgroup', include_columns=['cgroup', 'quantile'], table_sort=['quantile', 'cgroup'], width=1900, height=1400, gmean_round=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071d730b-7730-4b56-af1e-87b71aced5fb",
   "metadata": {},
   "source": [
    "# Task CPU residency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79085055-981d-4c20-b64f-ac4f6b899d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    task_residency_totals = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/tasks_residency_total.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/tasks_residency_total.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/tasks_residency_total.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/tasks_residency_total.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/tasks_residency_total.pqt'),\n",
    "    ]\n",
    "\n",
    "    task_residencies = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/tasks_residency.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/tasks_residency.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/tasks_residency.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/tasks_residency.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/tasks_residency.pqt'),\n",
    "    ]\n",
    "\n",
    "    \n",
    "    cpus = ['0.0', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0']\n",
    "    task_residency_total_combined = pd.concat(task_residency_totals).rename(columns={'Total':'total'})\n",
    "    task_residency_total_combined['wa_path'] = trim_wa_path(task_residency_total_combined['wa_path'].str)\n",
    "    task_residency_total_melt = pd.melt(task_residency_total_combined, id_vars=['iteration', 'wa_path', 'kernel'], value_vars=cpus).rename(columns={'variable':'cluster'})\n",
    "    task_residency_total_cluster_melt = pd.melt(task_residency_total_combined, id_vars=['iteration', 'wa_path', 'kernel'], value_vars=clusters_total).rename(columns={'cpu':'cluster'})\n",
    "\n",
    "    task_residencies_combined = pd.concat(task_residencies).rename(columns={'Total':'total'}).query(\"comm == 'AsyncTask #1'\")\n",
    "    task_residencies_combined['wa_path'] = trim_wa_path(task_residencies_combined['wa_path'].str)\n",
    "    task_residencies_combined_cluster_melt = pd.melt(task_residencies_combined, id_vars=['iteration', 'wa_path', 'kernel', 'comm'], value_vars=clusters_total).rename(columns={'cpu':'cluster'})\n",
    "    \n",
    "    display(task_residency_total_combined)\n",
    "except FileNotFoundError:\n",
    "    print('thermal.pqt not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e35e0-20b8-407f-84d8-e6d3240665b4",
   "metadata": {},
   "source": [
    "## Clusters - Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94294653-5942-4f60-bb0a-a68f8a57d6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hv.Dataset(task_residency_total_cluster_melt, ['iteration', hv.Dimension('wa_path', values=wa_paths), hv.Dimension('cluster', values=clusters_total)], 'value')\n",
    "layout = ds.to(hv.Curve, 'iteration', 'value').overlay('wa_path').opts(legend_position='bottom').layout('cluster').cols(4).opts(title='Mean cluster CPU residency')\n",
    "layout.opts(\n",
    "    opts.Curve(width=500, height=600, ylabel='time'),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520f8d16-035d-4f97-82c1-52b7bee677a5",
   "metadata": {},
   "source": [
    "## Clusters - Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49267373-ac8d-4518-a703-8da7130e2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(task_residency_total_cluster_melt, x='cluster', y='value', facet_col='metric', facet_col_wrap=2, title='Gmean cluster CPU residency', include_columns=['cluster'], width=1800, height=600, order_cluster=True, include_total=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0859391a",
   "metadata": {},
   "source": [
    "## Clusters - Per-task bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703cda52",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_cpu_residency = plot_gmean_bars(task_residencies_combined_cluster_melt, x='cluster', y='value', facet_col='comm', facet_col_wrap=2, title='Gmean cluster task CPU residency', include_columns=['cluster'], width=1800, height=600, order_cluster=True, include_total=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3230952c-a9dd-4f0f-b662-be931e6b2427",
   "metadata": {},
   "source": [
    "## CPUs - Line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf754295-f01c-486c-afd6-22ec0766621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = hv.Dataset(task_residency_total_melt, ['iteration', hv.Dimension('wa_path', values=wa_paths), hv.Dimension('cpu', values=cpus)], 'value')\n",
    "layout = ds.to(hv.Curve, 'iteration', 'value').overlay('wa_path').opts(legend_position='bottom').layout('cpu').cols(3).opts(title='Mean CPU residency')\n",
    "layout.opts(\n",
    "    opts.Curve(width=600, height=600, ylabel='time'),\n",
    ")\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c46b9-c9c9-4176-9b8b-733a3fdffaae",
   "metadata": {},
   "source": [
    "## CPUs - Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c746e1b-6642-406b-a179-8ac98cfaea90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(task_residency_total_melt, x='cpu', y='value', facet_col='metric', facet_col_wrap=2, title='Gmean CPU residency', width=1900, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820980c2-702a-44d7-9173-6973d3536826",
   "metadata": {},
   "source": [
    "# CPU residency - cgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40489438-137e-47d7-a67a-7f7a7bd190c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    cgroup_residency_totals = [\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_a + '/task_residency_cgroup_total.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_b + '/task_residency_cgroup_total.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_c + '/task_residency_cgroup_total.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_d + '/task_residency_cgroup_total.pqt'),\n",
    "        pd.read_parquet(BENCHMARK_PATH + benchmark_name_e + '/task_residency_cgroup_total.pqt'),\n",
    "    ]\n",
    "    \n",
    "    cpus = ['0.0', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0']\n",
    "    cgroup_residency_total_combined = pd.concat(cgroup_residency_totals).rename(columns={'Total':'total'})[['wa_path', 'cgroup', 'iteration', 'total', 'little', 'mid', 'big', '0.0', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0']]\n",
    "    cgroup_residency_total_combined['wa_path'] = trim_wa_path(cgroup_residency_total_combined['wa_path'].str)\n",
    "    cgroup_residency_total_melt = pd.melt(cgroup_residency_total_combined, id_vars=['iteration', 'wa_path', 'cgroup'], value_vars=cpus).rename(columns={'variable':'cluster'})\n",
    "    cgroup_residency_total_cluster_melt = pd.melt(cgroup_residency_total_combined, id_vars=['iteration', 'wa_path', 'cgroup'], value_vars=clusters_total).rename(columns={'cpu':'cluster'})\n",
    "    \n",
    "    display(cgroup_residency_total_combined)\n",
    "except FileNotFoundError:\n",
    "    print('task_residency_cgroup_total.pqt not found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996bec0-9c9f-40f7-8114-64d153d25daf",
   "metadata": {},
   "source": [
    "## Clusters - Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d0adf-fb93-4f2a-a301-2c818367248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(cgroup_residency_total_cluster_melt, x='cluster', y='value', facet_col='cgroup', facet_col_wrap=1, title='Gmean cluster CPU residency per-cgroup', width=1800, height=1100, include_columns=['cgroup', 'cluster'], table_sort=['cgroup', 'cluster'], order_cluster=True, include_total=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dd5125-1321-4257-b25a-9ff0c2a0faa5",
   "metadata": {},
   "source": [
    "## CPUs - Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac4603-381f-4623-ac48-40f43cccdd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gmean_bars(cgroup_residency_total_melt, x='cpu', y='value', facet_col='cgroup', facet_col_wrap=1, title='Gmean cgroup CPU residency', width=1800, height=1100, include_columns=['cgroup', 'cpu'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32231df0",
   "metadata": {},
   "source": [
    "# Summary - TLDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_parts = []\n",
    "\n",
    "try:\n",
    "    summary_benchmark_scores = benchmark_scores.copy()\n",
    "    summary_benchmark_scores['perc_diff'] = summary_benchmark_scores['perc_diff'].apply(lambda s: f\"({s})\")\n",
    "    summary_benchmark_scores['value'] = summary_benchmark_scores['value'] + \" \" + summary_benchmark_scores['perc_diff']\n",
    "    summary_benchmark_scores = summary_benchmark_scores.pivot(values='value', columns='kernel', index='metric').reset_index()[['metric'] + wa_paths]\n",
    "    summary_parts.append(summary_benchmark_scores)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    summary_power_usage = power_usage.copy().query(\"chan_name == 'total_power'\")\n",
    "    summary_power_usage['perc_diff'] = summary_power_usage['perc_diff'].apply(lambda s: f\"({s})\")\n",
    "    summary_power_usage['value'] = summary_power_usage['value'] + \" \" + summary_power_usage['perc_diff']\n",
    "    summary_power_usage = summary_power_usage.pivot(values='value', columns='kernel', index='chan_name').reset_index().rename(columns={'chan_name':'metric'})[['metric'] + wa_paths]\n",
    "    summary_parts.append(summary_power_usage)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    summary_ou = overutilized_mean.copy()\n",
    "    summary_ou['percentage'] = summary_ou['percentage'].apply(lambda x: f\"{x}%\")\n",
    "    summary_ou = summary_ou.pivot(values='percentage', columns='kernel', index='metric').reset_index()[['metric'] + wa_paths]\n",
    "    summary_parts.append(summary_ou)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    summary_thermal = thermal.copy()\n",
    "    summary_thermal['perc_diff'] = summary_thermal['perc_diff'].apply(lambda s: f\"({s})\")\n",
    "    summary_thermal['value'] = summary_thermal['value'] + \" \" + summary_thermal['perc_diff']\n",
    "    summary_thermal = summary_thermal.pivot(values='value', columns='kernel', index='cluster').reset_index().rename(columns={'cluster':'metric'})[['metric'] + wa_paths]\n",
    "    summary_thermal['metric'] = \"thermal (\" + summary_thermal['metric'] + \")\"\n",
    "    summary_parts.append(summary_thermal)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    summary_wakeup_latency = wakeup_latency.copy()\n",
    "    summary_wakeup_latency['perc_diff'] = summary_wakeup_latency['perc_diff'].apply(lambda s: f\"({s})\")\n",
    "    summary_wakeup_latency['comm'] = \"latency (\" + summary_wakeup_latency['comm'] + \")\"\n",
    "    summary_wakeup_latency['value'] = summary_wakeup_latency['value'] + \" \" + summary_wakeup_latency['perc_diff']\n",
    "    summary_wakeup_latency = summary_wakeup_latency.pivot(values='value', columns='kernel', index='comm').reset_index().rename(columns={'comm':'metric'})[['metric'] + wa_paths]\n",
    "    summary_parts.append(summary_wakeup_latency)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    summary_task_cpu_residency = task_cpu_residency.copy().query(\"cluster == 'total'\")\n",
    "    summary_task_cpu_residency['perc_diff'] = summary_task_cpu_residency['perc_diff'].apply(lambda s: f\"({s})\")\n",
    "    summary_task_cpu_residency['value'] = summary_task_cpu_residency['value'] + \" \" + summary_task_cpu_residency['perc_diff']\n",
    "    summary_task_cpu_residency = summary_task_cpu_residency.pivot(values='value', columns='kernel', index='comm').reset_index().rename(columns={'comm':'metric'})[['metric'] + wa_paths]\n",
    "    summary_task_cpu_residency['metric'] = \"CPU residency (\" + summary_task_cpu_residency['metric'] + \")\"\n",
    "    summary_parts.append(summary_task_cpu_residency)\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "summary = pd.concat(summary_parts).reset_index(drop=True)\n",
    "\n",
    "print('Geekbench 5')\n",
    "ptable(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
